{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import h5py\n",
    "\n",
    "import torch.optim as optim\n",
    "from torch import nn\n",
    "import torch.nn.functional as f\n",
    "from torch.nn.functional import one_hot, softmax\n",
    "\n",
    "import sys\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "sys.path.insert(0,'/hpc/compgen/projects/fragclass/analysis/mvivekanandan/script/madhu_scripts')\n",
    "\n",
    "import config\n",
    "import utils\n",
    "\n",
    "import importlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "import time"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "importlib.reload(utils)\n",
    "importlib.reload(config)\n",
    "\n",
    "#Set arguments from config file.\n",
    "arguments = {}\n",
    "arguments[\"trainingEnformerOutputStoreFile\"] = config.testFilePaths.get(\"trainingEnformerOutputStoreFile\")\n",
    "arguments[\"validationEnformerOutputStoreFile\"] = config.testFilePaths.get(\"validationEnformerOutputStoreFile\")\n",
    "arguments[\"testEnformerOutputStoreFile\"] = config.testFilePaths.get(\"testEnformerOutputStoreFile\")\n",
    "arguments[\"batchSize\"] = config.modelHyperParameters.get(\"batchSize\")\n",
    "arguments[\"learningRate\"] = config.modelHyperParameters.get(\"learningRate\")\n",
    "arguments[\"numberOfWorkers\"] = config.modelHyperParameters.get(\"numberOfWorkers\")\n",
    "arguments[\"numberEpochs\"] = config.modelHyperParameters.get(\"numberEpochs\")\n",
    "arguments[\"threshold\"] = config.modelHyperParameters.get(\"threshold\")\n",
    "arguments[\"storePlots\"] = config.modelGeneralConfigs.get(\"storePlots\")\n",
    "arguments[\"modelName\"] = config.modelGeneralConfigs.get(\"modelName\")\n",
    "arguments[\"trainingAndValidationOutputsDirectory\"] = config.filePaths.get(\"trainingAndValidationOutputsDirectory\")\n",
    "arguments[\"interchangeLabels\"] = config.modelGeneralConfigs.get(\"interchangeLabels\")\n",
    "arguments[\"useClassWeights\"] = config.modelGeneralConfigs.get(\"useClassWeights\")\n",
    "arguments[\"useCosineLearningFunction\"] = config.modelGeneralConfigs.get(\"useCosineLearningFunction\")\n",
    "arguments[\"trainingStartIndex\"] = config.modelGeneralConfigs.get(\"startIndexEnformerSamplesTraining\")\n",
    "arguments[\"trainingEndIndex\"] = config.modelGeneralConfigs.get(\"endIndexEnformerSamplesTraining\")\n",
    "arguments[\"validationStartIndex\"] = config.modelGeneralConfigs.get(\"startIndexEnformerSamplesValidation\")\n",
    "arguments[\"validationEndIndex\"] = config.modelGeneralConfigs.get(\"endIndexEnformerSamplesValidation\")\n",
    "arguments[\"normalizeFeatures\"] = config.modelGeneralConfigs.get(\"normalizeFeatures\")\n",
    "arguments[\"runWithControls\"] = config.modelGeneralConfigs.get(\"runWithControls\")\n",
    "print(arguments)\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"The device used is : {device}\")\n",
    "\n",
    "now = datetime.now()\n",
    "filename_extension = now.strftime(\"%d_%m_%H_%M_%S\")\n",
    "plotsDirectoryName = filename_extension + \"_\" + str(arguments[\"modelName\"])\n",
    "plotsDirectoryPath = os.path.join(arguments[\"trainingAndValidationOutputsDirectory\"], plotsDirectoryName)\n",
    "if(arguments[\"storePlots\"]):\n",
    "    os.mkdir(plotsDirectoryPath)\n",
    "\n",
    "masterList = []"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class BasicDenseLayer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BasicDenseLayer, self).__init__()\n",
    "        self.fc1 = nn.Linear(2 * 5313, 5000)\n",
    "        self.fc2 = nn.Linear(5000, 1000)\n",
    "        self.fc2 = nn.Linear(1000, 200)\n",
    "        self.fc3 = nn.Linear(200, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = f.relu(self.fc1(x))\n",
    "        x = f.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class SimpleDenseLayer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleDenseLayer, self).__init__()\n",
    "        self.fc1 = nn.Linear(25, 20)\n",
    "        self.fc2 = nn.Linear(20, 10)\n",
    "        self.fc3 = nn.Linear(10, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = f.relu(self.fc1(x))\n",
    "        x = f.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class EnformerOutputDataset(Dataset):\n",
    "    def __init__(self, sampleType):\n",
    "        self.sampleType = sampleType\n",
    "        self.enformerOutputDatasetName = sampleType + \"EnformerOutput\"\n",
    "        self.labelsDatasetName = sampleType + \"Labels\"\n",
    "\n",
    "        self.enformerOutputFileKey = sampleType + \"EnformerOutputStoreFile\"\n",
    "        self.enformerOutputFilePath = arguments[self.enformerOutputFileKey]\n",
    "        self.startIndex = arguments[sampleType + \"StartIndex\"]\n",
    "        self.endIndex = arguments[sampleType + \"EndIndex\"]\n",
    "        print(f\"inside init fn, start and end index for type {self.sampleType} are {self.startIndex} and {self.endIndex}\")\n",
    "\n",
    "    \"\"\"\n",
    "    The indexes fetched by dataloader iteration are not in order, because shuffling is set to true. This will not cause a mismatch\n",
    "    between the enformer output and the label. Because enformer output and label are fetched for the same index, so they will still\n",
    "    correspond to each other.\n",
    "    \"\"\"\n",
    "\n",
    "    def __getitem__(self, indices):\n",
    "        with h5py.File(self.enformerOutputFilePath, 'r') as f:\n",
    "            assert all(np.array(indices) >= self.startIndex), f\"Some indices are smaller than {self.startIndex} - {indices}\"\n",
    "            if self.endIndex != \"all\":\n",
    "                assert all(np.array(indices) < self.endIndex), f\"Some indices are greater than {self.endIndex} - {indices}\"\n",
    "\n",
    "            #Indices will be an array of indices. The size of the array is equal to the batch size. At a time, the entire batch will be loaded.\n",
    "            enformerOutput = f[self.enformerOutputDatasetName][indices][:, 0:25]\n",
    "            encoded_enformer_output = torch.tensor(np.float32(enformerOutput))\n",
    "\n",
    "            #Normalize each feature with zscore values.\n",
    "            if(arguments[\"normalizeFeatures\"]):\n",
    "                for i, single_batch in enumerate(encoded_enformer_output):\n",
    "                    mean, std = torch.mean(single_batch), torch.std(single_batch)\n",
    "                    encoded_enformer_output[i] = (single_batch - mean)/std\n",
    "\n",
    "            labels = f[self.labelsDatasetName][indices]\n",
    "\n",
    "        #For old coordinate files, the positives were incorrectly labelled as 0 and the negatives as 1.\n",
    "        if(arguments[\"interchangeLabels\"]):\n",
    "            positive_indices = np.where(labels == 0)\n",
    "            negative_indices = np.where(labels == 1)\n",
    "            labels[positive_indices] = 1\n",
    "            labels[negative_indices] = 0\n",
    "\n",
    "        #POSITIVE AND NEGATIVE CONTROL ADDITION.\n",
    "        #Replace some features in all positives with a higher value and the negatives with a negative value\n",
    "        if(arguments[\"runWithControls\"]):\n",
    "            for i, output in enumerate(encoded_enformer_output):\n",
    "                if labels[i] == 1:\n",
    "                    replacement_val = random.uniform(0.5, 1.5)\n",
    "                else:\n",
    "                    replacement_val = random.uniform(-0.5, -1.5)\n",
    "\n",
    "                replacementFeatList = [1, 2]\n",
    "                for j in replacementFeatList:\n",
    "                    output[j] = replacement_val\n",
    "\n",
    "                encoded_enformer_output[i] = output\n",
    "\n",
    "            # #The enoded enformer output only has 20 features. Append 0's for the rest of the features so that the dense layer matrix size is consistent with input\n",
    "            # nrows, ncols = encoded_enformer_output.shape\n",
    "            # zeroes = torch.zeros(nrows, 10606)\n",
    "            # encoded_enformer_output = torch.cat((encoded_enformer_output, zeroes), axis = 1)\n",
    "\n",
    "        return encoded_enformer_output, labels\n",
    "\n",
    "    def __len__(self):\n",
    "        with h5py.File(self.enformerOutputFilePath, 'r') as f:\n",
    "            if self.endIndex == \"all\":\n",
    "                labels = f[self.labelsDatasetName][self.startIndex:]\n",
    "            else:\n",
    "                labels = f[self.labelsDatasetName][self.startIndex:self.endIndex]\n",
    "\n",
    "            length_positives = (labels == 1).sum()\n",
    "            length_negatives = (labels == 0).sum()\n",
    "            arguments[self.sampleType + \"PositivesLength\"] = length_positives\n",
    "            arguments[self.sampleType + \"NegativesLength\"] = length_negatives\n",
    "            print(f\"Inside length of the {self.sampleType} dataset, the total number of samples is {length_positives + length_negatives}\")\n",
    "            return length_positives + length_negatives"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def getParametersDescription():\n",
    "    learningRate = arguments[\"learningRate\"]\n",
    "    batchSize = arguments[\"batchSize\"]\n",
    "    numTrainingPositives = arguments[\"trainingPositivesLength\"]\n",
    "    numTrainingNegatives = arguments[\"trainingNegativesLength\"]\n",
    "    numValidationPositives = arguments[\"validationPositivesLength\"]\n",
    "    numValidationNegatives = arguments[\"validationNegativesLength\"]\n",
    "    numTraining = numTrainingPositives + numTrainingNegatives\n",
    "    numValidation = numValidationPositives + numValidationNegatives\n",
    "\n",
    "    numLayers = 3\n",
    "    description = (f\"learning rate = {learningRate},\\n\"\n",
    "                   + f\"number of training samples = {numTraining} ({numTrainingPositives} positives and {numTrainingNegatives} negatives),\\n\"\n",
    "                    + f\"number of validation samples = {numValidation} ({numValidationPositives} positives and {numValidationNegatives} negatives),\\n\"\n",
    "                    + f\"batch size = {batchSize},\\n number of layers = {numLayers}\")\n",
    "\n",
    "    return description\n",
    "\n",
    "def storeLossFunctionPlot(training_loss_list, validation_loss_list):\n",
    "    xs_train = [x for x in range(len(training_loss_list))]\n",
    "    fig = plt.figure()\n",
    "    plot_description = getParametersDescription()\n",
    "    fig.text(.5, -0.3, plot_description, ha = 'center')\n",
    "    plt.plot(xs_train, training_loss_list, '-.', label = \"Training\")\n",
    "    xs_validation = [x for x in range(len(validation_loss_list))]\n",
    "    plt.plot(xs_validation, validation_loss_list, label = \"validation\")\n",
    "\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Cross Entropy Loss\")\n",
    "    plt.legend(loc=\"upper left\")\n",
    "    plt.title(\"Training and Validation Cross entropy loss over epochs.\")\n",
    "    if(arguments[\"storePlots\"]):\n",
    "        plotPath = os.path.join(plotsDirectoryPath, \"lossFunctionPlot\")\n",
    "        plt.savefig(plotPath, bbox_inches='tight')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\"\"\"\n",
    "Create a file(the name of the file has the current date and time) and save the state_dict of the model\n",
    "\"\"\"\n",
    "def saveModel(model):\n",
    "    if(arguments[\"storePlots\"]):\n",
    "        filepath = os.path.join(plotsDirectoryPath, \"modelState\")\n",
    "        f = open(filepath, \"x\")\n",
    "        torch.save(model.state_dict(), filepath)\n",
    "        f.close()\n",
    "\n",
    "#TODO To be removed once confusion matrix problems are fixed.\n",
    "def printDonorRecipientLabelsVsPredictions(true_labels, predictions, sampleType):\n",
    "    true_count_0 = 0\n",
    "    true_count_1 = 0\n",
    "\n",
    "    for i in range(len(true_labels)):\n",
    "        if(true_labels[i] == 0):\n",
    "            true_count_0 = true_count_0 + 1\n",
    "        if(true_labels[i] == 1):\n",
    "            true_count_1 = true_count_1 + 1\n",
    "\n",
    "    pred_count_0 = 0\n",
    "    pred_count_1 = 0\n",
    "\n",
    "    for i in range(len(predictions)):\n",
    "        if(predictions[i] == 0):\n",
    "            pred_count_0 = pred_count_0 + 1\n",
    "        if(predictions[i] == 1):\n",
    "            pred_count_1 = pred_count_1 + 1\n",
    "\n",
    "    print(f\"num of 0's and 1's predictions in the {sampleType} set is {pred_count_0} and {pred_count_1}\")\n",
    "\n",
    "def getClassWeights():\n",
    "    #If we store all training and validation labels, it might be too big a variable and slow things down.\n",
    "    #We are assuming that the first 10,000 samples are reflective of\n",
    "    with h5py.File(arguments[\"trainingEnformerOutputStoreFile\"], 'r') as f:\n",
    "        training_labels = f[\"trainingLabels\"][0:10000].flatten().tolist()\n",
    "\n",
    "    with h5py.File(arguments[\"validationEnformerOutputStoreFile\"], 'r') as f:\n",
    "        validation_labels = f[\"validationLabels\"][0:10000].flatten().tolist()\n",
    "\n",
    "    all_labels = training_labels + validation_labels\n",
    "    class_weights = compute_class_weight(class_weight = \"balanced\", classes = [0, 1], y = all_labels)\n",
    "    return class_weights\n",
    "\n",
    "#Once all errors with the function are fixed, move this inside objective function. This is pulled outside only to ensure\n",
    "#that the model variable is not lost if there are errors during saving.\n",
    "denseLayerModel = SimpleDenseLayer().to('cuda')\n",
    "\n",
    "def getConfusionMatrixAndLabels(true_labels, predictions, sampleType):\n",
    "\n",
    "    #TODO To be removed after testing is done\n",
    "    printDonorRecipientLabelsVsPredictions(true_labels, predictions, sampleType)\n",
    "\n",
    "    #Build the confusion matrix\n",
    "    cf_matrix = confusion_matrix(true_labels, predictions)\n",
    "    #train_cfmatrix_df = pd.DataFrame(data = training_cf_matrix, index = [\"true 0\", \"true 1\"], columns = [\"predicted 0\",\"predicted 1\"])\n",
    "\n",
    "    group_names = [\"True Neg\",\"False Pos\",\"False Neg\",\"True Pos\"]\n",
    "    group_counts = [\"{0:0.0f}\".format(value) for value in cf_matrix.flatten()]\n",
    "    group_percentages = [\"{0:.2%}\".format(value) for value in cf_matrix.flatten()/np.sum(cf_matrix)]\n",
    "    labels = [f\"{v1}\\n{v2}\\n{v3}\" for v1, v2, v3 in zip(group_names,group_counts,group_percentages)]\n",
    "    labels = np.asarray(labels).reshape(2,2)\n",
    "    return cf_matrix, labels\n",
    "\n",
    "def storeConfusionMatrixHeatMap(training_true_labels, validation_true_labels, training_predictions, validation_predictions):\n",
    "    fig, (ax1, ax2) = plt.subplots(1,2, figsize=(14, 8))\n",
    "    heatmap_description = getParametersDescription()\n",
    "    fig.text(.5, -0.1, heatmap_description, ha = 'center', fontsize=12)\n",
    "    training_cf_matrix, training_cf_matrix_labels = getConfusionMatrixAndLabels(training_true_labels, training_predictions, \"training\")\n",
    "    validation_cf_matrix, validation_cf_matrix_labels = getConfusionMatrixAndLabels(validation_true_labels, validation_predictions, \"validation\")\n",
    "    s1 = sns.heatmap(training_cf_matrix, annot=training_cf_matrix_labels, fmt = '', cmap=\"Blues\", ax=ax1, annot_kws={\"fontsize\":12})\n",
    "    s2 = sns.heatmap(validation_cf_matrix, annot=validation_cf_matrix_labels, fmt = '', cmap=\"Blues\", ax=ax2, annot_kws={\"fontsize\":12})\n",
    "    s1.set_xlabel(\"Predicted Label\", fontsize=12)\n",
    "    s1.set_ylabel(\"True Label\", fontsize=12)\n",
    "    s2.set_xlabel(\"Predicted Label\", fontsize=12)\n",
    "    s2.set_ylabel(\"True Label\", fontsize=12)\n",
    "    fig.subplots_adjust(hspace=0.75, wspace=0.75)\n",
    "\n",
    "    ax1.title.set_text(f'Training')\n",
    "    ax2.title.set_text(f'Validation')\n",
    "\n",
    "    if(arguments[\"storePlots\"]):\n",
    "        plotPath = os.path.join(plotsDirectoryPath, \"confusionMatrix\")\n",
    "        plt.savefig(plotPath, bbox_inches='tight')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def storePerformanceMetrics(true_labels, predictions, sampleType):\n",
    "    target_names = [\"donor\", \"recipient\"]\n",
    "    report = classification_report(true_labels, predictions, target_names=target_names, output_dict=True)\n",
    "    report_df = pd.DataFrame(data = report).transpose()\n",
    "    model_parameters_text = getParametersDescription()\n",
    "    parameters_df = {'donor': 'model parameters', 'recipient': model_parameters_text}\n",
    "    report_df = report_df.append(parameters_df, ignore_index = True)\n",
    "\n",
    "    if(arguments[\"storePlots\"]):\n",
    "        filename = \"performanceMetrics_\" + sampleType + \".csv\"\n",
    "        csv_path =  os.path.join(plotsDirectoryPath, filename)\n",
    "        report_df.to_csv(csv_path, index= True)\n",
    "\n",
    "def storeProbabilityFrequencyPlot(positive_training, negative_training, positive_validation, negative_validation):\n",
    "    positive_training_df = pd.DataFrame(positive_training, columns = [\"probabilities\"])\n",
    "    positive_training_df[\"type\"] = \"positive_training\"\n",
    "    negative_training_df = pd.DataFrame(negative_training, columns = [\"probabilities\"])\n",
    "    negative_training_df[\"type\"] = \"negative_training\"\n",
    "    positive_validation_df = pd.DataFrame(positive_validation, columns = [\"probabilities\"])\n",
    "    positive_validation_df[\"type\"] = \"positive_validation\"\n",
    "    negative_validation_df = pd.DataFrame(negative_validation, columns = [\"probabilities\"])\n",
    "    negative_validation_df[\"type\"] = \"negative_validation\"\n",
    "\n",
    "    df1 = pd.concat([positive_training_df, negative_training_df], ignore_index=True, axis=0)\n",
    "    df2 = pd.concat([positive_validation_df, negative_validation_df], ignore_index=True, axis=0)\n",
    "    prob_data_df = pd.concat([df1, df2], ignore_index=True, axis=0)\n",
    "\n",
    "    fig = plt.figure()\n",
    "    plot_description = getParametersDescription()\n",
    "    fig.text(.5, -0.1, plot_description, ha = 'center')\n",
    "    plt.figure(figsize=(10,5))\n",
    "    sns.histplot(data = prob_data_df, x = \"probabilities\", hue = \"type\", element = \"step\")\n",
    "    plt.yscale('log')\n",
    "    plt.title(\"Positive and Negative probabily distributions from model predictions. \")\n",
    "\n",
    "    if(arguments[\"storePlots\"]):\n",
    "        plotPath = os.path.join(plotsDirectoryPath, \"probabilityDistributionPlot\")\n",
    "        plt.savefig(plotPath, bbox_inches='tight')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "def plotPrecisionRecallCurve(training_positive_probs, training_true_labels, validation_positive_probs, validation_true_labels):\n",
    "    fig, (ax1, ax2) = plt.subplots(2, figsize=(6, 12))\n",
    "\n",
    "    training_precision, training_recall, training_thresholds = precision_recall_curve(training_true_labels, training_positive_probs)\n",
    "    ax1.plot(training_recall, training_precision)\n",
    "    ax1.title.set_text('Training')\n",
    "\n",
    "    validation_precision, validation_recall, validation_thresholds = precision_recall_curve(validation_true_labels, validation_positive_probs)\n",
    "    ax2.plot(validation_recall, validation_precision)\n",
    "    ax2.title.set_text('Validation')\n",
    "\n",
    "    plt.xlabel(\"Recall\")\n",
    "    plt.ylabel(\"Precision\")\n",
    "    fig.subplots_adjust(hspace=0.2, wspace=0.2)\n",
    "\n",
    "    if(arguments[\"storePlots\"]):\n",
    "        plotPath = os.path.join(plotsDirectoryPath, \"precisionRecallPlot\")\n",
    "        plt.savefig(plotPath, bbox_inches = \"tight\")\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "def getProbsForEachConfusionMatrixBlock(pos_probs, class_labels, threshold, sampleType):\n",
    "    true_pos = []\n",
    "    true_neg = []\n",
    "    false_pos = []\n",
    "    false_neg = []\n",
    "    for i, val in enumerate(class_labels):\n",
    "        if val == 1 and pos_probs[i] > threshold:\n",
    "            true_pos.append(pos_probs[i])\n",
    "        if val == 1 and pos_probs[i] < threshold:\n",
    "            false_neg.append(pos_probs[i])\n",
    "        if val == 0 and pos_probs[i] > threshold:\n",
    "            false_pos.append(pos_probs[i])\n",
    "        if val == 0 and pos_probs[i] < threshold:\n",
    "            true_neg.append(pos_probs[i])\n",
    "\n",
    "    # print(f\"Printing confusion matrix individual block probabilities for {sampleType}\")\n",
    "    # print(f\"true positives probs: size is {len(true_pos)} and {true_pos[1:20]}\")\n",
    "    # print(f\"false positives probs: size is {len(false_pos)} and {false_pos[1:20]}\")\n",
    "    # print(f\"true negatives probs: size is {len(true_neg)} and {true_neg[1:20]}\")\n",
    "    # print(f\"false negatives probs: size is {len(false_neg)} and {false_neg[1:20]}\")\n",
    "\n",
    "    true_pos_df = pd.DataFrame(true_pos, columns = [\"probabilities\"])\n",
    "    true_pos_df[\"type\"] = \"true_pos\"\n",
    "    false_pos_df = pd.DataFrame(false_pos, columns = [\"probabilities\"])\n",
    "    false_pos_df[\"type\"] = \"false_pos\"\n",
    "    true_neg_df = pd.DataFrame(true_neg, columns = [\"probabilities\"])\n",
    "    true_neg_df[\"type\"] = \"true_neg\"\n",
    "    false_neg_df = pd.DataFrame(false_neg, columns = [\"probabilities\"])\n",
    "    false_neg_df[\"type\"] = \"false_neg\"\n",
    "\n",
    "    df1 = pd.concat([true_pos_df, false_pos_df], ignore_index=True, axis=0)\n",
    "    df2 = pd.concat([true_neg_df, false_neg_df], ignore_index=True, axis=0)\n",
    "    final_probs_df = pd.concat([df1, df2], ignore_index=True, axis=0)\n",
    "\n",
    "    desc = f\"{sampleType} True Pos: {len(true_pos)}, False Pos: {len(false_pos)}, True Neg: {len(true_neg)}, False Neg: {len(false_neg)} \\n\"\n",
    "    return final_probs_df, desc\n",
    "\n",
    "def confsionMatrixLevelProbDistribtuionPlot(training_pos_probs, training_class_labels, valid_pos_probs,\n",
    "                                            valid_class_labels, threshold, epoch):\n",
    "\n",
    "    training_probs_df, training_desc = getProbsForEachConfusionMatrixBlock(training_pos_probs, training_class_labels, threshold, \"Training\")\n",
    "    validation_probs_df, validation_desc = getProbsForEachConfusionMatrixBlock(valid_pos_probs, valid_class_labels, threshold, \"Validation\")\n",
    "\n",
    "    fig_desc = training_desc + validation_desc\n",
    "\n",
    "    fig, (ax1, ax2) = plt.subplots(1,2, figsize=(9, 6))\n",
    "    s1 = sns.kdeplot(data = training_probs_df, x = \"probabilities\", hue = \"type\", ax = ax1)\n",
    "    s2 = sns.kdeplot(data = validation_probs_df, x = \"probabilities\", hue = \"type\", ax = ax2)\n",
    "    fig.text(.5, -0.2, fig_desc, ha = 'center')\n",
    "    ax1.title.set_text(f'Training Total epochs {epoch}')\n",
    "    ax2.title.set_text(f'Validation Total epochs {epoch}')\n",
    "\n",
    "    if(arguments[\"storePlots\"]):\n",
    "        plotPath = os.path.join(plotsDirectoryPath, \"confusionMatrixLevelProbabilityDistributionPlot\")\n",
    "        plt.savefig(plotPath, bbox_inches = \"tight\")\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "def plotLearningRate(scheduler_learning_rates, numEpochs, num_batches):\n",
    "    fig, ax = plt.subplots()\n",
    "    xs_learning_rate = [x for x in range(len(scheduler_learning_rates))]\n",
    "    plt.plot(xs_learning_rate, scheduler_learning_rates)\n",
    "    epoch_locations = []\n",
    "\n",
    "    for i in range(1, numEpochs):\n",
    "        epoch_locations.append(i * num_batches)\n",
    "\n",
    "    ax.vlines(x=epoch_locations, ymin = 0, ymax = max(scheduler_learning_rates), colors='r', ls=\"--\")\n",
    "    ax.set_xlabel(\"Training steps\")\n",
    "    ax.set_title(\"Learning rate curve used by optimizer\")\n",
    "    if(arguments[\"storePlots\"]):\n",
    "        plotPath = os.path.join(plotsDirectoryPath, \"learningRatePlot\")\n",
    "        plt.savefig(plotPath, bbox_inches = \"tight\")\n",
    "\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def getModelPredictionAndLoss(denseLayerModel, dataloader, criterion, lossList, threshold, predictions, isTraining=False, epoch=False, optimizer = False, learning_rates = False):\n",
    "    running_loss = 0.0\n",
    "\n",
    "    time_to_train = 0\n",
    "    start_time = time.time()\n",
    "    print(f\"Start time is {start_time}\")\n",
    "\n",
    "    trueLabels = []\n",
    "    all_positive_probs = []\n",
    "    all_negative_probs = []\n",
    "    violin_plot_positives =  np.zeros(25)\n",
    "    violin_plot_negatives = np.zeros(25)\n",
    "\n",
    "    for i, data in enumerate(dataloader, 0):\n",
    "        enformerPrediction, classLabels = data\n",
    "\n",
    "        if torch.cuda.is_available():\n",
    "            #While creating torch.tensor, device can be passed as cuda. But that was a suspect for GPU node running out of memory.\n",
    "            #After iterating through dataset and fetching each sample, send the labels and sequence to cuda\n",
    "            #The class labels should be of type integer.\n",
    "            enformerPrediction = enformerPrediction.to('cuda')\n",
    "            classLabels = classLabels.to(torch.int64).to('cuda')\n",
    "\n",
    "        #TODO modify sampler function\n",
    "        #Because we use the sampler, there is an extra dimension for the labels and enformer output. [1*128*10626].\n",
    "        #Take only the 1st element to remove the extra dimension.\n",
    "        classLabels = classLabels[0].flatten()\n",
    "        enformerPrediction = enformerPrediction[0]\n",
    "        for j, singleSample in enumerate(enformerPrediction):\n",
    "            if classLabels[j] == 1:\n",
    "                violin_plot_positives = np.row_stack([violin_plot_positives, singleSample.detach().cpu().numpy()])\n",
    "            else:\n",
    "                violin_plot_negatives = np.row_stack([violin_plot_negatives, singleSample.detach().cpu().numpy()])\n",
    "\n",
    "        #The class labels have to be encoded into probabilities of type floating point\n",
    "        probabilityLabels = one_hot(classLabels, num_classes=2).to(torch.float32)\n",
    "\n",
    "        trainStartTime = time.time()\n",
    "        modelPrediction = denseLayerModel(enformerPrediction)\n",
    "\n",
    "        #Apply softmax function to convert the prediction into probabilities between 0 and 1. This is used for plotting\n",
    "        #the frequency of the outcomes to know how sure the model was for different data points.\n",
    "        softmaxProbabilities = softmax(modelPrediction.cpu().detach()).numpy()\n",
    "        softmax_positive_probs = softmaxProbabilities.transpose()[1].flatten()\n",
    "        softmax_negative_probs = softmaxProbabilities.transpose()[0].flatten()\n",
    "        all_positive_probs.extend(softmax_positive_probs)\n",
    "        all_negative_probs.extend(softmax_negative_probs)\n",
    "\n",
    "        #Model prediction is a 2D array of size (batchSize * 2). The 2 values are the probabilities for the positive and negative for each sample in the batch.\n",
    "        # Whichever of the 2 labels has the highest probabilities is taken as the final predicted label of the model.\n",
    "        #If the probabilities added upto 1, this would count as taking 0.5 as the threshold for considering a class as the prediction.\n",
    "        #Iterate through all the positive probabilities predictions in the batch and extend the predictions list with all the predictions for the batch.\n",
    "        #TODO Uncomment this later - for now we are considering predictions for all epochs.\n",
    "        # if(epoch == arguments[\"numberEpochs\"]):\n",
    "        predictedLabels = []\n",
    "        for prob in softmax_positive_probs:\n",
    "            if prob > threshold:\n",
    "                predictedLabels.append(1)\n",
    "            else:\n",
    "                predictedLabels.append(0)\n",
    "\n",
    "        predictions.extend(predictedLabels)\n",
    "\n",
    "        trueLabels.extend(classLabels.cpu().numpy())\n",
    "\n",
    "        # Get cross entropy loss between model's prediction and true label.\n",
    "        loss = criterion(modelPrediction, probabilityLabels)\n",
    "\n",
    "        #If the model is being trained, then do backpropagation and calculate loss.\n",
    "        if(isTraining):\n",
    "            #zero grad is applicable only for optimizers and not for cosine annealing function schedulers.\n",
    "            if arguments[\"useCosineLearningFunction\"] != True:\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "            # Backward pass and calculate the gradients\n",
    "            loss.backward()\n",
    "\n",
    "            # Uses the gradients from backward pass to nudge the learning weights.\n",
    "            if arguments[\"useCosineLearningFunction\"]:\n",
    "                learning_rates.append(optimizer.get_lr())\n",
    "\n",
    "            optimizer.step()\n",
    "\n",
    "        time_to_train += (time.time() - trainStartTime)\n",
    "\n",
    "        # Print loss for every training set\n",
    "        # Check that the loss is continuosly decreasing over training samples.\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    end_time = time.time()\n",
    "    total_time = end_time - start_time\n",
    "    time_to_load = total_time - time_to_train\n",
    "\n",
    "    #The running_loss is the sum of individual losses for each batch.\n",
    "    #The average running loss for the epoch should be runnning_loss divided by the number of batches.\n",
    "    num_batches = len(dataloader)\n",
    "    avg_running_loss = running_loss/num_batches\n",
    "    print(f\"Average running loss for epoch {epoch} is {avg_running_loss}\\n\")\n",
    "    lossList.append(avg_running_loss)\n",
    "\n",
    "    #Make a violin plot of the values of enformer prediction to check if controls are working properly\n",
    "    if(epoch == 1):\n",
    "        print(f\"Making a violin plot .......\")\n",
    "        column_values = [str(i) for i in range(0, 25)]\n",
    "        positives_df = pd.DataFrame(data = violin_plot_positives[1:, :], columns = column_values)\n",
    "        plt.figure()\n",
    "        sns.violinplot(data = positives_df)\n",
    "        plt.show()\n",
    "        negatives_df = pd.DataFrame(data = violin_plot_negatives[1:, :], columns = column_values)\n",
    "        plt.figure()\n",
    "        sns.violinplot(data = negatives_df)\n",
    "        plt.show()\n",
    "\n",
    "    # print(f\"Average time to train model per batch for epoch {epoch} is {time_to_train/num_batches}\")\n",
    "    # print(f\"Average time to load input per batch for epoch {epoch} is {time_to_load/num_batches}\")\n",
    "    return all_positive_probs, all_negative_probs, trueLabels\n",
    "\n",
    "\n",
    "def objectiveFn(batchSize, learningRate, numWorkers, numEpochs):\n",
    "\n",
    "    #Training dataloader\n",
    "    trainingDataset = EnformerOutputDataset(\"training\")\n",
    "    rangeTrainingSampler = range(arguments[\"trainingStartIndex\"] , len(trainingDataset) + arguments[\"trainingStartIndex\"])\n",
    "    trainingsampler = torch.utils.data.BatchSampler(rangeTrainingSampler, batch_size=batchSize,\n",
    "                                            drop_last=False )\n",
    "    trainingDataloader = DataLoader(trainingDataset,  num_workers=numWorkers, sampler=trainingsampler)\n",
    "    print(f\"Finished getting training data loader,time for validation...\")\n",
    "    #Validation dataloader\n",
    "    validationDataset = EnformerOutputDataset(\"validation\")\n",
    "    rangeValidationSampler = range(arguments[\"validationStartIndex\"] , len(validationDataset) + arguments[\"validationStartIndex\"])\n",
    "    validation_sampler = torch.utils.data.BatchSampler(rangeValidationSampler, batch_size=batchSize,\n",
    "                                            drop_last=False )\n",
    "    validationDataloader = DataLoader(validationDataset, num_workers=numWorkers, sampler=validation_sampler)\n",
    "\n",
    "    training_num_batches = len(trainingDataloader)\n",
    "\n",
    "    #For training function, give higher weights to donor class because of sample number imbalance.\n",
    "    #For valdiation, treat both the classes equally.\n",
    "    if(arguments[\"useClassWeights\"]):\n",
    "        training_class_weights = getClassWeights()\n",
    "    else:\n",
    "        #If we are using a balanced dataset, there is no need to give weights to one class\n",
    "        training_class_weights = [1, 1]\n",
    "\n",
    "    print(f\"Training class weights are {training_class_weights}\")\n",
    "    # training_class_weights = [20.0, 1.0]\n",
    "    training_criterion = nn.CrossEntropyLoss(weight = torch.tensor(training_class_weights).to(device))\n",
    "\n",
    "    #Add weights for the validation as well, otherwise the training and validation loss will have different ranges and\n",
    "    #comparison will be difficult.\n",
    "    validation_criterion = nn.CrossEntropyLoss(weight = torch.tensor(training_class_weights).to(device))\n",
    "\n",
    "    optimizer = optim.Adam(denseLayerModel.parameters(), lr=learningRate)\n",
    "\n",
    "    if arguments[\"useCosineLearningFunction\"]:\n",
    "        optimizer_steps = (training_num_batches * numEpochs) #Number of steps in gradient descent.\n",
    "        scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, optimizer_steps, last_epoch = -1, eta_min=0)\n",
    "    else:\n",
    "        scheduler = optimizer\n",
    "\n",
    "    threshold = arguments[\"threshold\"]\n",
    "\n",
    "    training_loss_list = []\n",
    "    validation_loss_list = []\n",
    "\n",
    "    training_positive_probabilities_list = []\n",
    "    training_negative_probabilities_list = []\n",
    "    validation_positive_probabilities_list = []\n",
    "    validation_negative_probabilities_list = []\n",
    "\n",
    "    scheduler_learning_rates = []\n",
    "\n",
    "    #Training the model and validating for each epoch\n",
    "    for epoch in range(1, numEpochs + 1):\n",
    "        print(f\"Starting training for epoch {epoch}\")\n",
    "\n",
    "        training_predictions = []\n",
    "        validation_predictions = []\n",
    "\n",
    "        #Training\n",
    "        train_positive_probs, train_negative_probs, train_class_labels = getModelPredictionAndLoss(denseLayerModel, trainingDataloader, training_criterion,\n",
    "            training_loss_list, threshold, training_predictions, True, epoch, scheduler, scheduler_learning_rates)\n",
    "\n",
    "        print(f\"Finished training for epoch {epoch}. Starting validations\")\n",
    "\n",
    "        training_positive_probabilities_list.extend(train_positive_probs)\n",
    "        training_negative_probabilities_list.extend(train_negative_probs)\n",
    "\n",
    "        #Validation\n",
    "        with torch.no_grad():\n",
    "            validation_positive_probs, validation_negative_probs, validation_class_labels = getModelPredictionAndLoss(denseLayerModel, validationDataloader, validation_criterion,\n",
    "                validation_loss_list, threshold, validation_predictions, False, epoch)\n",
    "\n",
    "            validation_positive_probabilities_list.extend(validation_positive_probs)\n",
    "            validation_negative_probabilities_list.extend(validation_negative_probs)\n",
    "\n",
    "\n",
    "    print(f\"Completed training and validation. Saving model and plotting loss function graphs. \")\n",
    "\n",
    "    saveModel(denseLayerModel)\n",
    "    storeLossFunctionPlot(training_loss_list, validation_loss_list)\n",
    "    storePerformanceMetrics(train_class_labels, training_predictions, \"training\")\n",
    "    storePerformanceMetrics(validation_class_labels, validation_predictions, \"validation\")\n",
    "    storeProbabilityFrequencyPlot(training_positive_probabilities_list, training_negative_probabilities_list,\n",
    "                                    validation_positive_probabilities_list, validation_negative_probabilities_list)\n",
    "    confsionMatrixLevelProbDistribtuionPlot(training_positive_probabilities_list, train_class_labels,\n",
    "                                                validation_positive_probabilities_list, validation_class_labels, 0.5, arguments[\"numberEpochs\"])\n",
    "\n",
    "\n",
    "    #Plot confusion matrix and precision recall plot only for the probabilities in the last epoch\n",
    "    storeConfusionMatrixHeatMap(train_class_labels, validation_class_labels, training_predictions, validation_predictions)\n",
    "    plotPrecisionRecallCurve(train_positive_probs, train_class_labels, validation_positive_probs, validation_class_labels)\n",
    "    if(arguments[\"useCosineLearningFunction\"]):\n",
    "        plotLearningRate(scheduler_learning_rates, numEpochs, training_num_batches)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
