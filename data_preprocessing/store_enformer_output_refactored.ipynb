{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "### This Jupyter file is meant for testing code to get Enformer output for all the cfDNA coordinate files in a given directory, and store the output into H5PY files. For more details on what each functions are doing and the whole workflow, refer to storeEnformerOutput.py file"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arguments in file sequenceDataset are {'coordStoreDirectory': '/hpc/compgen/projects/fragclass/analysis/mvivekanandan/output/subsetClassBalancedCoordinateFiles', 'refGenomePath': '/hpc/compgen/projects/fragclass/raw/hg19_genome/hg19_ch1-22_XYM.fa', 'usePaddingForSequenceOutput': None, 'modelInputSequenceSize': 'enformer', 'runWithControls': False, 'usePaddingForCnn': False, 'trainingCoordsDatasetName': 'trainingCoords', 'validationCoordsDatasetName': 'validationCoords', 'testCoordsDatasetName': 'testCoords', 'trainingLabelsDatasetName': 'trainingLabels', 'validationLabelsDatasetName': 'validationLabels', 'testLabelsDatasetName': 'testLabels'}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import pandas as pd\n",
    "\n",
    "from enformer_pytorch import Enformer\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import h5py\n",
    "import sys\n",
    "\n",
    "sys.path.insert(0,'/hpc/compgen/projects/fragclass/analysis/mvivekanandan/script/madhu_scripts')\n",
    "\n",
    "import config\n",
    "import utils\n",
    "import sequenceDataset\n",
    "\n",
    "import importlib   \n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The device used is : cuda\n",
      "arguments in file sequenceDataset are {'coordStoreDirectory': '/hpc/compgen/projects/fragclass/analysis/mvivekanandan/output/subsetClassBalancedCoordinateFiles', 'refGenomePath': '/hpc/compgen/projects/fragclass/raw/hg19_genome/hg19_ch1-22_XYM.fa', 'usePaddingForSequenceOutput': None, 'modelInputSequenceSize': 'enformer', 'runWithControls': False, 'usePaddingForCnn': False, 'trainingCoordsDatasetName': 'trainingCoords', 'validationCoordsDatasetName': 'validationCoords', 'testCoordsDatasetName': 'testCoords', 'trainingLabelsDatasetName': 'trainingLabels', 'validationLabelsDatasetName': 'validationLabels', 'testLabelsDatasetName': 'testLabels'}\n",
      "{'refGenomePath': '/hpc/compgen/projects/fragclass/raw/hg19_genome/hg19_ch1-22_XYM.fa', 'coordStoreDirectory': '/hpc/compgen/projects/fragclass/analysis/mvivekanandan/output/subsetClassBalancedCoordinateFiles', 'trainingEnformerOuputStoreFile': '/hpc/compgen/projects/fragclass/analysis/mvivekanandan/output/EnformerOutputs/training_test.hdf5', 'validationEnformerOuputStoreFile': '/hpc/compgen/projects/fragclass/analysis/mvivekanandan/output/EnformerOutputs/validation_test.hdf5', 'testEnformerOuputStoreFile': '/hpc/compgen/projects/fragclass/analysis/mvivekanandan/output/EnformerOutputs/some_test_test_file.hdf5', 'trainingMetadata': None, 'validationMetadata': None, 'testMetadata': None, 'enformerBatchSize': 8, 'enformerNumberOfWorkers': 12, 'file_sharing_strategy': 'file_system', 'enformerOutputFileCompression': 8, 'enformerOutputFileChunkSize': 200, 'trainingLabelsDatasetName': 'trainingLabels', 'validationLabelsDatasetName': 'validationLabels', 'testLabelsDatasetName': 'testLabels', 'trainingEnformerOutputDatasetName': 'trainingEnformerOutput', 'validationEnformerOutputDatasetName': 'validationEnformerOutput', 'testEnformerOutputDatasetName': 'testEnformerOutput'}\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"The device used is : {device}\")\n",
    "\n",
    "importlib.reload(config)\n",
    "importlib.reload(utils)\n",
    "importlib.reload(sequenceDataset)\n",
    "\n",
    "#Set arguments from config file.\n",
    "arguments = {}\n",
    "#File paths\n",
    "arguments[\"refGenomePath\"] = config.filePaths.get(\"refGenomePath\")\n",
    "arguments[\"coordStoreDirectory\"] = config.filePaths.get(\"coordStoreDirectory\")\n",
    "arguments[\"trainingEnformerOuputStoreFile\"] = config.testFilePaths.get(\"trainingEnformerOutputStoreFile\")\n",
    "arguments[\"validationEnformerOuputStoreFile\"] = config.testFilePaths.get(\"validationEnformerOutputStoreFile\")\n",
    "arguments[\"testEnformerOuputStoreFile\"] = config.testFilePaths.get(\"testEnformerOutputStoreFile\")\n",
    "arguments[\"trainingMetadata\"] = config.filePaths.get(\"trainingMetadata\")\n",
    "arguments[\"validationMetadata\"] = config.filePaths.get(\"validationMetadata\")\n",
    "arguments[\"testMetadata\"] = config.filePaths.get(\"testMetadata\")\n",
    "\n",
    "#Enformer output model hyperparameters\n",
    "arguments[\"enformerBatchSize\"] = config.modelHyperParameters.get(\"enformerBatchSize\")\n",
    "arguments[\"enformerNumberOfWorkers\"] = config.modelHyperParameters.get(\"enformerNumberOfWorkers\")\n",
    "\n",
    "#General configs\n",
    "arguments[\"file_sharing_strategy\"] = config.modelGeneralConfigs.get(\"fileSharingStrategy\")\n",
    "arguments[\"enformerOutputFileCompression\"] = config.modelGeneralConfigs.get(\"enformerOutputFileCompression\")\n",
    "arguments[\"enformerOutputFileChunkSize\"] = config.modelGeneralConfigs.get(\"enformerOutputFileChunkSize\")\n",
    "\n",
    "#Datasets\n",
    "arguments[\"trainingLabelsDatasetName\"] = config.datasetNames.get(\"trainingLabels\")\n",
    "arguments[\"validationLabelsDatasetName\"] = config.datasetNames.get(\"validationLabels\")\n",
    "arguments[\"testLabelsDatasetName\"] = config.datasetNames.get(\"testLabels\")\n",
    "arguments[\"trainingEnformerOutputDatasetName\"] = config.datasetNames.get(\"trainingEnformerOutput\")\n",
    "arguments[\"validationEnformerOutputDatasetName\"] = config.datasetNames.get(\"validationEnformerOutput\")\n",
    "arguments[\"testEnformerOutputDatasetName\"] = config.datasetNames.get(\"testEnformerOutput\")\n",
    "\n",
    "print(arguments)\n",
    "fileIndicesDict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getEnformerPredictions(enformer_model, sequence, bins, ntracks, batchNum):\n",
    "    with torch.no_grad():\n",
    "        startBins = bins[0]\n",
    "        endBins = bins[1]\n",
    "\n",
    "        #For each output from enformer, get the right bin. \n",
    "        full_enformer_output = enformer_model(sequence)['human']\n",
    "    \n",
    "    #the enformer prediction is still in the GPU (since we sent the enformer model and one hot encoded sequence to the GPU. Numpy arrays are not supported in the GPU(GPU probably supports only tensors). So we pass the enformer prediction to CPU and convert it into a numpy array.\n",
    "    #Detach is used to remove the gradients from the predictions. Gradients are similar to the weights of the model. In our case, we are only interested in the predictions and not the model training, so we remove the gradients to save space.\n",
    "    full_enformer_output = full_enformer_output.detach().cpu()\n",
    "    final_enformer_output = torch.empty(1, 2, ntracks)\n",
    "    dims = full_enformer_output.shape\n",
    "    \n",
    "    for i in range(dims[0]):\n",
    "        #endBin + 1 because of the way torch index based slicing works. x[:, 1:3, :] will give the 1st and 2nd index\n",
    "        #So the end index in slicing should always be 1 greater than the last index we want. \n",
    "        # print(f\"For iteration {i}, startBins is {startBins[i]} and endBin is {endBins[i]}\")\n",
    "        assert full_enformer_output.numel() != True, f\"Something is wrong !! The enformer pedictions is empty for batch {batchNum} and within batch iteration {i}\"\n",
    "        single_sample_output = full_enformer_output[i, int(startBins[i]):int(endBins[i]) + 1, :].reshape(1, 2, ntracks)\n",
    "        # print(f\"Shape of single sample enformer output is {single_sample_output.shape}\")\n",
    "        final_enformer_output = torch.cat([final_enformer_output,single_sample_output], dim=0)\n",
    "    \n",
    "    #The 1st value in the final enformer output is the empty tensor we created for concatenation purposes. \n",
    "    final_enformer_output = final_enformer_output[1:, :, :]\n",
    "    # print(f\"Shape of the enformer prediction after taking bins is {final_enformer_output.shape}\")\n",
    "    # print(f\"Printing the output shape from enformer {pretrained_output.shape}\", flush=True)\n",
    "\n",
    "    #Combine enformer outputs from 2 bins into a single long output. Each bin, each track is a feature. So the total\n",
    "    #number of features for training is num_bins * num_tracks_per_bin. All features can be combined in a\n",
    "    #single 1D tensor array. The other dimension will be the batch size.\n",
    "    batch_size, nbins, ntracks = final_enformer_output.shape\n",
    "\n",
    "    final_enformer_output = torch.reshape(final_enformer_output, (batch_size, nbins * ntracks))\n",
    "    return final_enformer_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Look into how much h5py content can be compressed. Greater the compression, longer the time needed to read it again.\n",
    "def storeAsH5pyFile(sampleType, numSamples, numEnformerOuputSingleSample, createDataset = False, h5_file = False, \n",
    "                    enformerOutputToStore=False, labelsToStore=False, currentIndex = False):\n",
    "   \n",
    "   enformerOutputDatasetName = arguments[sampleType + \"EnformerOutputDatasetName\"]\n",
    "   labelsDatasetName = arguments[sampleType + \"LabelsDatasetName\"]\n",
    "   enformerOutputFilePath = arguments[sampleType + \"EnformerOuputStoreFile\"]\n",
    "   print(f\"enformer output file path is {enformerOutputFilePath}\")\n",
    "   \n",
    "   #If we opening the H5PY file for the 1st time then create the dataset and return the file. \n",
    "   if createDataset: \n",
    "      print(\"This is the 1st time. Inside createDataset\")\n",
    "\n",
    "      if h5_file == False:\n",
    "         h5_file = h5py.File(enformerOutputFilePath, \"w-\")\n",
    "\n",
    "      h5_file.create_dataset(enformerOutputDatasetName,  (numSamples, numEnformerOuputSingleSample),\n",
    "                                    compression=\"gzip\", compression_opts=arguments[\"enformerOutputFileCompression\"], \n",
    "                                    chunks = (arguments[\"enformerOutputFileChunkSize\"], numEnformerOuputSingleSample))\n",
    "      h5_file.create_dataset(labelsDatasetName, (numSamples, 1), compression=\"gzip\", \n",
    "                             compression_opts=arguments[\"enformerOutputFileCompression\"], \n",
    "                              chunks = (arguments[\"enformerOutputFileChunkSize\"], 1))\n",
    "      return(h5_file)\n",
    "\n",
    "   else:\n",
    "      sizeOfOutputToStore = len(labelsToStore)\n",
    "      endIndex = currentIndex + sizeOfOutputToStore\n",
    "      h5_file[enformerOutputDatasetName][(currentIndex):(endIndex),:] = enformerOutputToStore\n",
    "      h5_file[labelsDatasetName][(currentIndex):(endIndex),:] = labelsToStore\n",
    "      return endIndex\n",
    "\n",
    "def storeMetadataAsCsv(sampleType, filepathData, indexData):\n",
    "   metadataFileKey = sampleType + \"Metadata\"\n",
    "   metadataFilePath = arguments[metadataFileKey]\n",
    "   metadata = pd.DataFrame({'og_file': filepathData, 'indexInFile':indexData})\n",
    "   print(f\"Shape of metadata df after all batches are done is {metadata.shape}\")\n",
    "   metadata.to_csv(metadataFilePath, sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_worker_sharing_strategy(worker_id: int) -> None:\n",
    "    torch.multiprocessing.set_sharing_strategy(arguments[\"file_sharing_strategy\"])\n",
    "\n",
    "#The function returns 2 numpy arrays. The 1st numpy array is the enformer output for all cfdna fragments. The second numpy array is the array of labels for all cfDNA fragments.\n",
    "def storeEnformerOutput(sampleType, h5_file = False):\n",
    "    nbins = 2\n",
    "    ntracks = 5313\n",
    "\n",
    "    #Set the model to eval mode first and then send it to cuda. This prevents the GPU node from running out of memory.\n",
    "    enformerModel = Enformer.from_pretrained('EleutherAI/enformer-official-rough', use_checkpointing = True).eval()\n",
    "    enformerModel = enformerModel.to(device)\n",
    "    \n",
    "    enformerInputDataset = sequenceDataset.SequenceDataset(sampleType)\n",
    "    enformerInputDataloader = DataLoader(enformerInputDataset, batch_size=arguments[\"enformerBatchSize\"], \n",
    "                                         num_workers=arguments[\"enformerNumberOfWorkers\"],\n",
    "                                         shuffle=True, worker_init_fn=set_worker_sharing_strategy)\n",
    "    \n",
    "    numSamples = len(enformerInputDataset)\n",
    "\n",
    "    #Create the datasets for storing enformer output. \n",
    "    h5_file = storeAsH5pyFile(sampleType, numSamples, nbins * ntracks, True, h5_file)\n",
    "    \n",
    "    filepath_data, index_data = [], []\n",
    "    currentH5Index = 0\n",
    "\n",
    "    for i, data in enumerate(enformerInputDataloader, 0):\n",
    "        print(f\"Processing data for batch {i}\", flush = True)\n",
    "        \n",
    "        #Store the filepath and the index within file to a separate CSV file. This is to ensure that we are able to locate the sample\n",
    "        #so we can access the metadata(from original coordinate bed file) associated with the sample. \n",
    "        #filepath and index should have all the samples data from this batch. \n",
    "        encodedSequence, label, bins, filepath, indexWithinFile, _= data\n",
    "\n",
    "        filepath_data.extend(filepath)\n",
    "        index_data.extend(indexWithinFile)\n",
    "\n",
    "        # print(f\"Printing the shape of the encoded sequence {encodedSequence.shape}\", flush = True)\n",
    "        # print(f\"Printing the shape of label {label.shape}\")\n",
    "        encodedSequence = encodedSequence.to(device)\n",
    "        \n",
    "        #Will be of the shape [batch_size * 10626]\n",
    "        enformerPrediction = getEnformerPredictions(enformerModel, encodedSequence, bins, ntracks, i).detach().cpu().numpy()\n",
    "    \n",
    "        #The data is getting too big to load, round off enformer predictions to 3 decimal places. \n",
    "        enformerPrediction = np.around(enformerPrediction, decimals=3)\n",
    "        print(f\"Finished processsing batch {i}, enformer prediction shape is {enformerPrediction.shape}\")\n",
    "        \n",
    "        \"\"\"\n",
    "        H5 file contents are updated every batch. To ensure that the contents are not overwritten every batch, store with indices. \n",
    "        The indices given are ascending order numbers starting from 0, this ensures that the shuffled order is maintained while storing in H5PY file. \n",
    "        \"\"\"\n",
    "        currentH5Index = storeAsH5pyFile(sampleType, numSamples, nbins * ntracks, False, h5_file, enformerPrediction, label, currentH5Index)\n",
    "        print(f\"The number of samples stored in H5PY file so far is {currentH5Index}\")\n",
    "\n",
    "    h5_file.close()\n",
    "\n",
    "    #Store the filename and index within the file for each sample as a CSV file for later use. \n",
    "    storeMetadataAsCsv(sampleType, filepath_data, index_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def verifyStoredEnformerTracks():\n",
    "    \"\"\"\n",
    "    Assertions to be done for stored enformer tracks \n",
    "    1. Total share of enformer output file shoud be [num_samples_coordinate_files * 10626]\n",
    "    1. Number of positives and negatives in enformer file = number of positives in the coordinate store directory\n",
    "    2. Total shape of the enformer tracks \n",
    "    \"\"\"\n",
    "    coordsDir = arguments[\"coordStoreDirectory\"]\n",
    "    sampleCounts = {}\n",
    "    sampleCounts[\"training\"] = [0, 0]\n",
    "    sampleCounts[\"validation\"] = [0,0]\n",
    "    sampleCounts[\"test\"] = [0,0]\n",
    "\n",
    "    for filename in os.listdir(coordsDir):\n",
    "        filepath = os.path.join(coordsDir, filename)\n",
    "        with h5py.File(filepath, 'r') as f:\n",
    "            for sampleType in [\"training\", \"validation\", \"test\"]:\n",
    "                labelsDataset = sampleType + \"Labels\"\n",
    "                labels = f[labelsDataset][:]\n",
    "                sampleCounts[sampleType][0] += (labels == 1).sum()\n",
    "                sampleCounts[sampleType][1] += (labels == 0).sum()\n",
    "    \n",
    "    x = sampleCounts[\"training\"]\n",
    "    y = sampleCounts[\"validation\"]\n",
    "    z = sampleCounts[\"test\"]\n",
    "\n",
    "    print(f\"Finished going over the coordinate files, the numbers are {x}, {y} and {z}\")\n",
    "\n",
    "    outputFilesDict = {}\n",
    "    # outputFilesDict[\"training\"] = arguments[\"trainingEnformerOuputStoreFile\"]\n",
    "    outputFilesDict[\"validation\"] = arguments[\"validationEnformerOuputStoreFile\"]\n",
    "    # outputFilesDict[\"test\"] = arguments[\"testEnformerOuputStoreFile\"]\n",
    "    \n",
    "    for sampleType, file in outputFilesDict.items(): \n",
    "        with h5py.File(file, 'r') as f:\n",
    "            enformerOutputDataset = sampleType + \"EnformerOutput\"\n",
    "            labelsDataset = sampleType + \"Labels\"\n",
    "            enformerDataShape = f[enformerOutputDataset][:].shape\n",
    "            labels = f[labelsDataset][:]\n",
    "\n",
    "            print(f\"Enformer output shape is {enformerDataShape}\")\n",
    "            #Assertion 1 Verify that shape of enformer output is as expected: \n",
    "            assert enformerDataShape[0] == sampleCounts[sampleType][0] + sampleCounts[sampleType][1], (f\"The total number of samples in enformer output\"+\n",
    "                                                                                                       f\" file({enformerDataShape[0]}) does not match the \"+\n",
    "                                                                                                       \"total samples in coordinate store directory\"\n",
    "                                                                                                       f\"({sampleCounts[sampleType][0] + sampleCounts[sampleType][1]})\")\n",
    "            assert enformerDataShape[1] == 10626, (f\"The number of enformer tracks in the output file({enformerDataShape[1]}) \"+\n",
    "                                                    \"for samples is not 10626 !!\")\n",
    "\n",
    "            #Assertion - 2 Verify that the number of positives and negatives match \n",
    "            numPositives = (labels == 1).sum()\n",
    "            numNegatives = (labels == 0).sum()\n",
    "            print(f\"Num positives and negatives in enformer for sample {sampleType} are {numPositives} and {numNegatives}\")\n",
    "            print(f\"Num pos and neg in coord for sampleType {sampleType} are {sampleCounts[sampleType][0]} and {sampleCounts[sampleType][1]}\")\n",
    "\n",
    "            assert numPositives == sampleCounts[sampleType][0], (f\"The number of positives in enformer file({numPositives}) \"+\n",
    "                                                                 f\"does not match the original positives {sampleCounts[sampleType][0]}\")\n",
    "            assert numNegatives == sampleCounts[sampleType][1], (f\"The number of negatives in enformer file({numNegatives}) \"+\n",
    "                                                                 f\"does not match the original negatives {sampleCounts[sampleType][1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of samples in all files combined is 212720\n",
      "enformer output file path is /hpc/compgen/projects/fragclass/analysis/mvivekanandan/output/EnformerOutputs/training_test.hdf5\n",
      "This is the 1st time. Inside createDataset\n",
      "Processing data for batch 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/hpc/compgen/users/mvivekanandan/miniconda/envs/fragenv/lib/python3.10/site-packages/torch/utils/checkpoint.py:31: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished processsing batch 0, enformer prediction shape is (8, 10626)\n",
      "enformer output file path is /hpc/compgen/projects/fragclass/analysis/mvivekanandan/output/EnformerOutputs/training_test.hdf5\n",
      "The number of samples stored in H5PY file so far is 8\n",
      "Processing data for batch 1\n",
      "Finished processsing batch 1, enformer prediction shape is (8, 10626)\n",
      "enformer output file path is /hpc/compgen/projects/fragclass/analysis/mvivekanandan/output/EnformerOutputs/training_test.hdf5\n",
      "The number of samples stored in H5PY file so far is 16\n",
      "Processing data for batch 2\n",
      "Finished processsing batch 2, enformer prediction shape is (8, 10626)\n",
      "enformer output file path is /hpc/compgen/projects/fragclass/analysis/mvivekanandan/output/EnformerOutputs/training_test.hdf5\n",
      "The number of samples stored in H5PY file so far is 24\n",
      "Processing data for batch 3\n",
      "Finished processsing batch 3, enformer prediction shape is (8, 10626)\n",
      "enformer output file path is /hpc/compgen/projects/fragclass/analysis/mvivekanandan/output/EnformerOutputs/training_test.hdf5\n",
      "The number of samples stored in H5PY file so far is 32\n",
      "Processing data for batch 4\n",
      "Finished processsing batch 4, enformer prediction shape is (8, 10626)\n",
      "enformer output file path is /hpc/compgen/projects/fragclass/analysis/mvivekanandan/output/EnformerOutputs/training_test.hdf5\n",
      "The number of samples stored in H5PY file so far is 40\n",
      "Processing data for batch 5\n",
      "Finished processsing batch 5, enformer prediction shape is (8, 10626)\n",
      "enformer output file path is /hpc/compgen/projects/fragclass/analysis/mvivekanandan/output/EnformerOutputs/training_test.hdf5\n",
      "The number of samples stored in H5PY file so far is 48\n",
      "Processing data for batch 6\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[8], line 3\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[39mif\u001B[39;00m \u001B[39m__name__\u001B[39m \u001B[39m==\u001B[39m \u001B[39m'\u001B[39m\u001B[39m__main__\u001B[39m\u001B[39m'\u001B[39m:\n\u001B[1;32m      2\u001B[0m     \u001B[39m#Get enformer Output for training data \u001B[39;00m\n\u001B[0;32m----> 3\u001B[0m     storeEnformerOutput(\u001B[39m\"\u001B[39;49m\u001B[39mtraining\u001B[39;49m\u001B[39m\"\u001B[39;49m)\n\u001B[1;32m      4\u001B[0m     \u001B[39m# storeEnformerOutput(\"validation\")\u001B[39;00m\n\u001B[1;32m      5\u001B[0m     \u001B[39m# storeEnformerOutput(\"test\")\u001B[39;00m\n\u001B[1;32m      6\u001B[0m     verifyStoredEnformerTracks()\n",
      "Cell \u001B[0;32mIn[5], line 42\u001B[0m, in \u001B[0;36mstoreEnformerOutput\u001B[0;34m(sampleType, h5_file)\u001B[0m\n\u001B[1;32m     39\u001B[0m encodedSequence \u001B[39m=\u001B[39m encodedSequence\u001B[39m.\u001B[39mto(device)\n\u001B[1;32m     41\u001B[0m \u001B[39m#Will be of the shape [batch_size * 10626]\u001B[39;00m\n\u001B[0;32m---> 42\u001B[0m enformerPrediction \u001B[39m=\u001B[39m getEnformerPredictions(enformerModel, encodedSequence, bins, ntracks, i)\u001B[39m.\u001B[39mdetach()\u001B[39m.\u001B[39mcpu()\u001B[39m.\u001B[39mnumpy()\n\u001B[1;32m     44\u001B[0m \u001B[39m#The data is getting too big to load, round off enformer predictions to 3 decimal places. \u001B[39;00m\n\u001B[1;32m     45\u001B[0m enformerPrediction \u001B[39m=\u001B[39m np\u001B[39m.\u001B[39maround(enformerPrediction, decimals\u001B[39m=\u001B[39m\u001B[39m3\u001B[39m)\n",
      "Cell \u001B[0;32mIn[3], line 7\u001B[0m, in \u001B[0;36mgetEnformerPredictions\u001B[0;34m(enformer_model, sequence, bins, ntracks, batchNum)\u001B[0m\n\u001B[1;32m      4\u001B[0m     endBins \u001B[39m=\u001B[39m bins[\u001B[39m1\u001B[39m]\n\u001B[1;32m      6\u001B[0m     \u001B[39m#For each output from enformer, get the right bin. \u001B[39;00m\n\u001B[0;32m----> 7\u001B[0m     full_enformer_output \u001B[39m=\u001B[39m enformer_model(sequence)[\u001B[39m'\u001B[39m\u001B[39mhuman\u001B[39m\u001B[39m'\u001B[39m]\n\u001B[1;32m      9\u001B[0m \u001B[39m#the enformer prediction is still in the GPU (since we sent the enformer model and one hot encoded sequence to the GPU. Numpy arrays are not supported in the GPU(GPU probably supports only tensors). So we pass the enformer prediction to CPU and convert it into a numpy array.\u001B[39;00m\n\u001B[1;32m     10\u001B[0m \u001B[39m#Detach is used to remove the gradients from the predictions. Gradients are similar to the weights of the model. In our case, we are only interested in the predictions and not the model training, so we remove the gradients to save space.\u001B[39;00m\n\u001B[1;32m     11\u001B[0m full_enformer_output \u001B[39m=\u001B[39m full_enformer_output\u001B[39m.\u001B[39mdetach()\u001B[39m.\u001B[39mcpu()\n",
      "File \u001B[0;32m/hpc/compgen/users/mvivekanandan/miniconda/envs/fragenv/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1496\u001B[0m \u001B[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1497\u001B[0m \u001B[39m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1498\u001B[0m \u001B[39mif\u001B[39;00m \u001B[39mnot\u001B[39;00m (\u001B[39mself\u001B[39m\u001B[39m.\u001B[39m_backward_hooks \u001B[39mor\u001B[39;00m \u001B[39mself\u001B[39m\u001B[39m.\u001B[39m_backward_pre_hooks \u001B[39mor\u001B[39;00m \u001B[39mself\u001B[39m\u001B[39m.\u001B[39m_forward_hooks \u001B[39mor\u001B[39;00m \u001B[39mself\u001B[39m\u001B[39m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1499\u001B[0m         \u001B[39mor\u001B[39;00m _global_backward_pre_hooks \u001B[39mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1500\u001B[0m         \u001B[39mor\u001B[39;00m _global_forward_hooks \u001B[39mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1501\u001B[0m     \u001B[39mreturn\u001B[39;00m forward_call(\u001B[39m*\u001B[39;49margs, \u001B[39m*\u001B[39;49m\u001B[39m*\u001B[39;49mkwargs)\n\u001B[1;32m   1502\u001B[0m \u001B[39m# Do not call functions when jit is used\u001B[39;00m\n\u001B[1;32m   1503\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[39m=\u001B[39m [], []\n",
      "File \u001B[0;32m/hpc/compgen/users/mvivekanandan/miniconda/envs/fragenv/lib/python3.10/site-packages/enformer_pytorch/modeling_enformer.py:423\u001B[0m, in \u001B[0;36mEnformer.forward\u001B[0;34m(self, x, target, return_corr_coef, return_embeddings, return_only_embeddings, head, target_length)\u001B[0m\n\u001B[1;32m    420\u001B[0m     \u001B[39mself\u001B[39m\u001B[39m.\u001B[39mset_target_length(target_length)\n\u001B[1;32m    422\u001B[0m trunk_fn \u001B[39m=\u001B[39m \u001B[39mself\u001B[39m\u001B[39m.\u001B[39mtrunk_checkpointed \u001B[39mif\u001B[39;00m \u001B[39mself\u001B[39m\u001B[39m.\u001B[39muse_checkpointing \u001B[39melse\u001B[39;00m \u001B[39mself\u001B[39m\u001B[39m.\u001B[39m_trunk\n\u001B[0;32m--> 423\u001B[0m x \u001B[39m=\u001B[39m trunk_fn(x)\n\u001B[1;32m    425\u001B[0m \u001B[39mif\u001B[39;00m no_batch:\n\u001B[1;32m    426\u001B[0m     x \u001B[39m=\u001B[39m rearrange(x, \u001B[39m'\u001B[39m\u001B[39m() ... -> ...\u001B[39m\u001B[39m'\u001B[39m)\n",
      "File \u001B[0;32m/hpc/compgen/users/mvivekanandan/miniconda/envs/fragenv/lib/python3.10/site-packages/enformer_pytorch/modeling_enformer.py:393\u001B[0m, in \u001B[0;36mEnformer.trunk_checkpointed\u001B[0;34m(self, x)\u001B[0m\n\u001B[1;32m    391\u001B[0m x \u001B[39m=\u001B[39m \u001B[39mself\u001B[39m\u001B[39m.\u001B[39mconv_tower(x)\n\u001B[1;32m    392\u001B[0m x \u001B[39m=\u001B[39m rearrange(x, \u001B[39m'\u001B[39m\u001B[39mb d n -> b n d\u001B[39m\u001B[39m'\u001B[39m)\n\u001B[0;32m--> 393\u001B[0m x \u001B[39m=\u001B[39m checkpoint_sequential(\u001B[39mself\u001B[39;49m\u001B[39m.\u001B[39;49mtransformer, \u001B[39mlen\u001B[39;49m(\u001B[39mself\u001B[39;49m\u001B[39m.\u001B[39;49mtransformer), x)\n\u001B[1;32m    394\u001B[0m x \u001B[39m=\u001B[39m \u001B[39mself\u001B[39m\u001B[39m.\u001B[39mcrop_final(x)\n\u001B[1;32m    395\u001B[0m x \u001B[39m=\u001B[39m \u001B[39mself\u001B[39m\u001B[39m.\u001B[39mfinal_pointwise(x)\n",
      "File \u001B[0;32m/hpc/compgen/users/mvivekanandan/miniconda/envs/fragenv/lib/python3.10/site-packages/torch/utils/checkpoint.py:330\u001B[0m, in \u001B[0;36mcheckpoint_sequential\u001B[0;34m(functions, segments, input, use_reentrant, **kwargs)\u001B[0m\n\u001B[1;32m    328\u001B[0m \u001B[39mfor\u001B[39;00m start \u001B[39min\u001B[39;00m \u001B[39mrange\u001B[39m(\u001B[39m0\u001B[39m, segment_size \u001B[39m*\u001B[39m (segments \u001B[39m-\u001B[39m \u001B[39m1\u001B[39m), segment_size):\n\u001B[1;32m    329\u001B[0m     end \u001B[39m=\u001B[39m start \u001B[39m+\u001B[39m segment_size \u001B[39m-\u001B[39m \u001B[39m1\u001B[39m\n\u001B[0;32m--> 330\u001B[0m     \u001B[39minput\u001B[39m \u001B[39m=\u001B[39m checkpoint(\n\u001B[1;32m    331\u001B[0m         run_function(start, end, functions),\n\u001B[1;32m    332\u001B[0m         \u001B[39minput\u001B[39;49m,\n\u001B[1;32m    333\u001B[0m         use_reentrant\u001B[39m=\u001B[39;49muse_reentrant,\n\u001B[1;32m    334\u001B[0m         preserve_rng_state\u001B[39m=\u001B[39;49mpreserve\n\u001B[1;32m    335\u001B[0m     )\n\u001B[1;32m    336\u001B[0m \u001B[39mreturn\u001B[39;00m run_function(end \u001B[39m+\u001B[39m \u001B[39m1\u001B[39m, \u001B[39mlen\u001B[39m(functions) \u001B[39m-\u001B[39m \u001B[39m1\u001B[39m, functions)(\u001B[39minput\u001B[39m)\n",
      "File \u001B[0;32m/hpc/compgen/users/mvivekanandan/miniconda/envs/fragenv/lib/python3.10/site-packages/torch/utils/checkpoint.py:249\u001B[0m, in \u001B[0;36mcheckpoint\u001B[0;34m(function, use_reentrant, *args, **kwargs)\u001B[0m\n\u001B[1;32m    246\u001B[0m     \u001B[39mraise\u001B[39;00m \u001B[39mValueError\u001B[39;00m(\u001B[39m\"\u001B[39m\u001B[39mUnexpected keyword arguments: \u001B[39m\u001B[39m\"\u001B[39m \u001B[39m+\u001B[39m \u001B[39m\"\u001B[39m\u001B[39m,\u001B[39m\u001B[39m\"\u001B[39m\u001B[39m.\u001B[39mjoin(arg \u001B[39mfor\u001B[39;00m arg \u001B[39min\u001B[39;00m kwargs))\n\u001B[1;32m    248\u001B[0m \u001B[39mif\u001B[39;00m use_reentrant:\n\u001B[0;32m--> 249\u001B[0m     \u001B[39mreturn\u001B[39;00m CheckpointFunction\u001B[39m.\u001B[39;49mapply(function, preserve, \u001B[39m*\u001B[39;49margs)\n\u001B[1;32m    250\u001B[0m \u001B[39melse\u001B[39;00m:\n\u001B[1;32m    251\u001B[0m     \u001B[39mreturn\u001B[39;00m _checkpoint_without_reentrant(\n\u001B[1;32m    252\u001B[0m         function,\n\u001B[1;32m    253\u001B[0m         preserve,\n\u001B[1;32m    254\u001B[0m         \u001B[39m*\u001B[39margs,\n\u001B[1;32m    255\u001B[0m         \u001B[39m*\u001B[39m\u001B[39m*\u001B[39mkwargs,\n\u001B[1;32m    256\u001B[0m     )\n",
      "File \u001B[0;32m/hpc/compgen/users/mvivekanandan/miniconda/envs/fragenv/lib/python3.10/site-packages/torch/autograd/function.py:506\u001B[0m, in \u001B[0;36mFunction.apply\u001B[0;34m(cls, *args, **kwargs)\u001B[0m\n\u001B[1;32m    503\u001B[0m \u001B[39mif\u001B[39;00m \u001B[39mnot\u001B[39;00m torch\u001B[39m.\u001B[39m_C\u001B[39m.\u001B[39m_are_functorch_transforms_active():\n\u001B[1;32m    504\u001B[0m     \u001B[39m# See NOTE: [functorch vjp and autograd interaction]\u001B[39;00m\n\u001B[1;32m    505\u001B[0m     args \u001B[39m=\u001B[39m _functorch\u001B[39m.\u001B[39mutils\u001B[39m.\u001B[39munwrap_dead_wrappers(args)\n\u001B[0;32m--> 506\u001B[0m     \u001B[39mreturn\u001B[39;00m \u001B[39msuper\u001B[39;49m()\u001B[39m.\u001B[39;49mapply(\u001B[39m*\u001B[39;49margs, \u001B[39m*\u001B[39;49m\u001B[39m*\u001B[39;49mkwargs)  \u001B[39m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m    508\u001B[0m \u001B[39mif\u001B[39;00m \u001B[39mcls\u001B[39m\u001B[39m.\u001B[39msetup_context \u001B[39m==\u001B[39m _SingleLevelFunction\u001B[39m.\u001B[39msetup_context:\n\u001B[1;32m    509\u001B[0m     \u001B[39mraise\u001B[39;00m \u001B[39mRuntimeError\u001B[39;00m(\n\u001B[1;32m    510\u001B[0m         \u001B[39m'\u001B[39m\u001B[39mIn order to use an autograd.Function with functorch transforms \u001B[39m\u001B[39m'\u001B[39m\n\u001B[1;32m    511\u001B[0m         \u001B[39m'\u001B[39m\u001B[39m(vmap, grad, jvp, jacrev, ...), it must override the setup_context \u001B[39m\u001B[39m'\u001B[39m\n\u001B[1;32m    512\u001B[0m         \u001B[39m'\u001B[39m\u001B[39mstaticmethod. For more details, please see \u001B[39m\u001B[39m'\u001B[39m\n\u001B[1;32m    513\u001B[0m         \u001B[39m'\u001B[39m\u001B[39mhttps://pytorch.org/docs/master/notes/extending.func.html\u001B[39m\u001B[39m'\u001B[39m)\n",
      "File \u001B[0;32m/hpc/compgen/users/mvivekanandan/miniconda/envs/fragenv/lib/python3.10/site-packages/torch/utils/checkpoint.py:107\u001B[0m, in \u001B[0;36mCheckpointFunction.forward\u001B[0;34m(ctx, run_function, preserve_rng_state, *args)\u001B[0m\n\u001B[1;32m    104\u001B[0m ctx\u001B[39m.\u001B[39msave_for_backward(\u001B[39m*\u001B[39mtensor_inputs)\n\u001B[1;32m    106\u001B[0m \u001B[39mwith\u001B[39;00m torch\u001B[39m.\u001B[39mno_grad():\n\u001B[0;32m--> 107\u001B[0m     outputs \u001B[39m=\u001B[39m run_function(\u001B[39m*\u001B[39;49margs)\n\u001B[1;32m    108\u001B[0m \u001B[39mreturn\u001B[39;00m outputs\n",
      "File \u001B[0;32m/hpc/compgen/users/mvivekanandan/miniconda/envs/fragenv/lib/python3.10/site-packages/torch/utils/checkpoint.py:318\u001B[0m, in \u001B[0;36mcheckpoint_sequential.<locals>.run_function.<locals>.forward\u001B[0;34m(input)\u001B[0m\n\u001B[1;32m    316\u001B[0m \u001B[39mdef\u001B[39;00m \u001B[39mforward\u001B[39m(\u001B[39minput\u001B[39m):\n\u001B[1;32m    317\u001B[0m     \u001B[39mfor\u001B[39;00m j \u001B[39min\u001B[39;00m \u001B[39mrange\u001B[39m(start, end \u001B[39m+\u001B[39m \u001B[39m1\u001B[39m):\n\u001B[0;32m--> 318\u001B[0m         \u001B[39minput\u001B[39m \u001B[39m=\u001B[39m functions[j](\u001B[39minput\u001B[39;49m)\n\u001B[1;32m    319\u001B[0m     \u001B[39mreturn\u001B[39;00m \u001B[39minput\u001B[39m\n",
      "File \u001B[0;32m/hpc/compgen/users/mvivekanandan/miniconda/envs/fragenv/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1496\u001B[0m \u001B[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1497\u001B[0m \u001B[39m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1498\u001B[0m \u001B[39mif\u001B[39;00m \u001B[39mnot\u001B[39;00m (\u001B[39mself\u001B[39m\u001B[39m.\u001B[39m_backward_hooks \u001B[39mor\u001B[39;00m \u001B[39mself\u001B[39m\u001B[39m.\u001B[39m_backward_pre_hooks \u001B[39mor\u001B[39;00m \u001B[39mself\u001B[39m\u001B[39m.\u001B[39m_forward_hooks \u001B[39mor\u001B[39;00m \u001B[39mself\u001B[39m\u001B[39m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1499\u001B[0m         \u001B[39mor\u001B[39;00m _global_backward_pre_hooks \u001B[39mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1500\u001B[0m         \u001B[39mor\u001B[39;00m _global_forward_hooks \u001B[39mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1501\u001B[0m     \u001B[39mreturn\u001B[39;00m forward_call(\u001B[39m*\u001B[39;49margs, \u001B[39m*\u001B[39;49m\u001B[39m*\u001B[39;49mkwargs)\n\u001B[1;32m   1502\u001B[0m \u001B[39m# Do not call functions when jit is used\u001B[39;00m\n\u001B[1;32m   1503\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[39m=\u001B[39m [], []\n",
      "File \u001B[0;32m/hpc/compgen/users/mvivekanandan/miniconda/envs/fragenv/lib/python3.10/site-packages/torch/nn/modules/container.py:217\u001B[0m, in \u001B[0;36mSequential.forward\u001B[0;34m(self, input)\u001B[0m\n\u001B[1;32m    215\u001B[0m \u001B[39mdef\u001B[39;00m \u001B[39mforward\u001B[39m(\u001B[39mself\u001B[39m, \u001B[39minput\u001B[39m):\n\u001B[1;32m    216\u001B[0m     \u001B[39mfor\u001B[39;00m module \u001B[39min\u001B[39;00m \u001B[39mself\u001B[39m:\n\u001B[0;32m--> 217\u001B[0m         \u001B[39minput\u001B[39m \u001B[39m=\u001B[39m module(\u001B[39minput\u001B[39;49m)\n\u001B[1;32m    218\u001B[0m     \u001B[39mreturn\u001B[39;00m \u001B[39minput\u001B[39m\n",
      "File \u001B[0;32m/hpc/compgen/users/mvivekanandan/miniconda/envs/fragenv/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1496\u001B[0m \u001B[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1497\u001B[0m \u001B[39m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1498\u001B[0m \u001B[39mif\u001B[39;00m \u001B[39mnot\u001B[39;00m (\u001B[39mself\u001B[39m\u001B[39m.\u001B[39m_backward_hooks \u001B[39mor\u001B[39;00m \u001B[39mself\u001B[39m\u001B[39m.\u001B[39m_backward_pre_hooks \u001B[39mor\u001B[39;00m \u001B[39mself\u001B[39m\u001B[39m.\u001B[39m_forward_hooks \u001B[39mor\u001B[39;00m \u001B[39mself\u001B[39m\u001B[39m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1499\u001B[0m         \u001B[39mor\u001B[39;00m _global_backward_pre_hooks \u001B[39mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1500\u001B[0m         \u001B[39mor\u001B[39;00m _global_forward_hooks \u001B[39mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1501\u001B[0m     \u001B[39mreturn\u001B[39;00m forward_call(\u001B[39m*\u001B[39;49margs, \u001B[39m*\u001B[39;49m\u001B[39m*\u001B[39;49mkwargs)\n\u001B[1;32m   1502\u001B[0m \u001B[39m# Do not call functions when jit is used\u001B[39;00m\n\u001B[1;32m   1503\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[39m=\u001B[39m [], []\n",
      "File \u001B[0;32m/hpc/compgen/users/mvivekanandan/miniconda/envs/fragenv/lib/python3.10/site-packages/enformer_pytorch/modeling_enformer.py:128\u001B[0m, in \u001B[0;36mResidual.forward\u001B[0;34m(self, x, **kwargs)\u001B[0m\n\u001B[1;32m    127\u001B[0m \u001B[39mdef\u001B[39;00m \u001B[39mforward\u001B[39m(\u001B[39mself\u001B[39m, x, \u001B[39m*\u001B[39m\u001B[39m*\u001B[39mkwargs):\n\u001B[0;32m--> 128\u001B[0m     \u001B[39mreturn\u001B[39;00m \u001B[39mself\u001B[39;49m\u001B[39m.\u001B[39;49mfn(x, \u001B[39m*\u001B[39;49m\u001B[39m*\u001B[39;49mkwargs) \u001B[39m+\u001B[39m x\n",
      "File \u001B[0;32m/hpc/compgen/users/mvivekanandan/miniconda/envs/fragenv/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1496\u001B[0m \u001B[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1497\u001B[0m \u001B[39m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1498\u001B[0m \u001B[39mif\u001B[39;00m \u001B[39mnot\u001B[39;00m (\u001B[39mself\u001B[39m\u001B[39m.\u001B[39m_backward_hooks \u001B[39mor\u001B[39;00m \u001B[39mself\u001B[39m\u001B[39m.\u001B[39m_backward_pre_hooks \u001B[39mor\u001B[39;00m \u001B[39mself\u001B[39m\u001B[39m.\u001B[39m_forward_hooks \u001B[39mor\u001B[39;00m \u001B[39mself\u001B[39m\u001B[39m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1499\u001B[0m         \u001B[39mor\u001B[39;00m _global_backward_pre_hooks \u001B[39mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1500\u001B[0m         \u001B[39mor\u001B[39;00m _global_forward_hooks \u001B[39mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1501\u001B[0m     \u001B[39mreturn\u001B[39;00m forward_call(\u001B[39m*\u001B[39;49margs, \u001B[39m*\u001B[39;49m\u001B[39m*\u001B[39;49mkwargs)\n\u001B[1;32m   1502\u001B[0m \u001B[39m# Do not call functions when jit is used\u001B[39;00m\n\u001B[1;32m   1503\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[39m=\u001B[39m [], []\n",
      "File \u001B[0;32m/hpc/compgen/users/mvivekanandan/miniconda/envs/fragenv/lib/python3.10/site-packages/torch/nn/modules/container.py:217\u001B[0m, in \u001B[0;36mSequential.forward\u001B[0;34m(self, input)\u001B[0m\n\u001B[1;32m    215\u001B[0m \u001B[39mdef\u001B[39;00m \u001B[39mforward\u001B[39m(\u001B[39mself\u001B[39m, \u001B[39minput\u001B[39m):\n\u001B[1;32m    216\u001B[0m     \u001B[39mfor\u001B[39;00m module \u001B[39min\u001B[39;00m \u001B[39mself\u001B[39m:\n\u001B[0;32m--> 217\u001B[0m         \u001B[39minput\u001B[39m \u001B[39m=\u001B[39m module(\u001B[39minput\u001B[39;49m)\n\u001B[1;32m    218\u001B[0m     \u001B[39mreturn\u001B[39;00m \u001B[39minput\u001B[39m\n",
      "File \u001B[0;32m/hpc/compgen/users/mvivekanandan/miniconda/envs/fragenv/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1496\u001B[0m \u001B[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1497\u001B[0m \u001B[39m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1498\u001B[0m \u001B[39mif\u001B[39;00m \u001B[39mnot\u001B[39;00m (\u001B[39mself\u001B[39m\u001B[39m.\u001B[39m_backward_hooks \u001B[39mor\u001B[39;00m \u001B[39mself\u001B[39m\u001B[39m.\u001B[39m_backward_pre_hooks \u001B[39mor\u001B[39;00m \u001B[39mself\u001B[39m\u001B[39m.\u001B[39m_forward_hooks \u001B[39mor\u001B[39;00m \u001B[39mself\u001B[39m\u001B[39m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1499\u001B[0m         \u001B[39mor\u001B[39;00m _global_backward_pre_hooks \u001B[39mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1500\u001B[0m         \u001B[39mor\u001B[39;00m _global_forward_hooks \u001B[39mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1501\u001B[0m     \u001B[39mreturn\u001B[39;00m forward_call(\u001B[39m*\u001B[39;49margs, \u001B[39m*\u001B[39;49m\u001B[39m*\u001B[39;49mkwargs)\n\u001B[1;32m   1502\u001B[0m \u001B[39m# Do not call functions when jit is used\u001B[39;00m\n\u001B[1;32m   1503\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[39m=\u001B[39m [], []\n",
      "File \u001B[0;32m/hpc/compgen/users/mvivekanandan/miniconda/envs/fragenv/lib/python3.10/site-packages/enformer_pytorch/modeling_enformer.py:248\u001B[0m, in \u001B[0;36mAttention.forward\u001B[0;34m(self, x)\u001B[0m\n\u001B[1;32m    244\u001B[0m q \u001B[39m=\u001B[39m q \u001B[39m*\u001B[39m \u001B[39mself\u001B[39m\u001B[39m.\u001B[39mscale\n\u001B[1;32m    246\u001B[0m content_logits \u001B[39m=\u001B[39m einsum(\u001B[39m'\u001B[39m\u001B[39mb h i d, b h j d -> b h i j\u001B[39m\u001B[39m'\u001B[39m, q \u001B[39m+\u001B[39m \u001B[39mself\u001B[39m\u001B[39m.\u001B[39mrel_content_bias, k)\n\u001B[0;32m--> 248\u001B[0m positions \u001B[39m=\u001B[39m get_positional_embed(n, \u001B[39mself\u001B[39;49m\u001B[39m.\u001B[39;49mnum_rel_pos_features, device)\n\u001B[1;32m    249\u001B[0m positions \u001B[39m=\u001B[39m \u001B[39mself\u001B[39m\u001B[39m.\u001B[39mpos_dropout(positions)\n\u001B[1;32m    250\u001B[0m rel_k \u001B[39m=\u001B[39m \u001B[39mself\u001B[39m\u001B[39m.\u001B[39mto_rel_k(positions)\n",
      "File \u001B[0;32m/hpc/compgen/users/mvivekanandan/miniconda/envs/fragenv/lib/python3.10/site-packages/enformer_pytorch/modeling_enformer.py:105\u001B[0m, in \u001B[0;36mget_positional_embed\u001B[0;34m(seq_len, feature_size, device)\u001B[0m\n\u001B[1;32m    103\u001B[0m embeddings \u001B[39m=\u001B[39m []\n\u001B[1;32m    104\u001B[0m \u001B[39mfor\u001B[39;00m fn \u001B[39min\u001B[39;00m feature_functions:\n\u001B[0;32m--> 105\u001B[0m     embeddings\u001B[39m.\u001B[39mappend(fn(distances, num_basis_per_class, seq_len))\n\u001B[1;32m    107\u001B[0m embeddings \u001B[39m=\u001B[39m torch\u001B[39m.\u001B[39mcat(embeddings, dim \u001B[39m=\u001B[39m \u001B[39m-\u001B[39m\u001B[39m1\u001B[39m)\n\u001B[1;32m    108\u001B[0m embeddings \u001B[39m=\u001B[39m torch\u001B[39m.\u001B[39mcat((embeddings, torch\u001B[39m.\u001B[39msign(distances)[\u001B[39m.\u001B[39m\u001B[39m.\u001B[39m\u001B[39m.\u001B[39m, \u001B[39mNone\u001B[39;00m] \u001B[39m*\u001B[39m embeddings), dim \u001B[39m=\u001B[39m \u001B[39m-\u001B[39m\u001B[39m1\u001B[39m)\n",
      "File \u001B[0;32m/hpc/compgen/users/mvivekanandan/miniconda/envs/fragenv/lib/python3.10/site-packages/enformer_pytorch/modeling_enformer.py:56\u001B[0m, in \u001B[0;36mget_positional_features_exponential\u001B[0;34m(positions, features, seq_len, min_half_life)\u001B[0m\n\u001B[1;32m     54\u001B[0m \u001B[39mdef\u001B[39;00m \u001B[39mget_positional_features_exponential\u001B[39m(positions, features, seq_len, min_half_life \u001B[39m=\u001B[39m \u001B[39m3.\u001B[39m):\n\u001B[1;32m     55\u001B[0m     max_range \u001B[39m=\u001B[39m math\u001B[39m.\u001B[39mlog(seq_len) \u001B[39m/\u001B[39m math\u001B[39m.\u001B[39mlog(\u001B[39m2.\u001B[39m)\n\u001B[0;32m---> 56\u001B[0m     half_life \u001B[39m=\u001B[39m \u001B[39m2\u001B[39;49m \u001B[39m*\u001B[39;49m\u001B[39m*\u001B[39;49m torch\u001B[39m.\u001B[39;49mlinspace(min_half_life, max_range, features, device \u001B[39m=\u001B[39;49m positions\u001B[39m.\u001B[39;49mdevice)\n\u001B[1;32m     57\u001B[0m     half_life \u001B[39m=\u001B[39m half_life[\u001B[39mNone\u001B[39;00m, \u001B[39m.\u001B[39m\u001B[39m.\u001B[39m\u001B[39m.\u001B[39m]\n\u001B[1;32m     58\u001B[0m     positions \u001B[39m=\u001B[39m positions\u001B[39m.\u001B[39mabs()[\u001B[39m.\u001B[39m\u001B[39m.\u001B[39m\u001B[39m.\u001B[39m, \u001B[39mNone\u001B[39;00m]\n",
      "File \u001B[0;32m/hpc/compgen/users/mvivekanandan/miniconda/envs/fragenv/lib/python3.10/site-packages/torch/_tensor.py:40\u001B[0m, in \u001B[0;36m_handle_torch_function_and_wrap_type_error_to_not_implemented.<locals>.wrapped\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     38\u001B[0m     \u001B[39mif\u001B[39;00m has_torch_function(args):\n\u001B[1;32m     39\u001B[0m         \u001B[39mreturn\u001B[39;00m handle_torch_function(wrapped, args, \u001B[39m*\u001B[39margs, \u001B[39m*\u001B[39m\u001B[39m*\u001B[39mkwargs)\n\u001B[0;32m---> 40\u001B[0m     \u001B[39mreturn\u001B[39;00m f(\u001B[39m*\u001B[39;49margs, \u001B[39m*\u001B[39;49m\u001B[39m*\u001B[39;49mkwargs)\n\u001B[1;32m     41\u001B[0m \u001B[39mexcept\u001B[39;00m \u001B[39mTypeError\u001B[39;00m:\n\u001B[1;32m     42\u001B[0m     \u001B[39mreturn\u001B[39;00m \u001B[39mNotImplemented\u001B[39m\n",
      "File \u001B[0;32m/hpc/compgen/users/mvivekanandan/miniconda/envs/fragenv/lib/python3.10/site-packages/torch/_tensor.py:878\u001B[0m, in \u001B[0;36mTensor.__rpow__\u001B[0;34m(self, other)\u001B[0m\n\u001B[1;32m    875\u001B[0m \u001B[39m@_handle_torch_function_and_wrap_type_error_to_not_implemented\u001B[39m\n\u001B[1;32m    876\u001B[0m \u001B[39mdef\u001B[39;00m \u001B[39m__rpow__\u001B[39m(\u001B[39mself\u001B[39m, other):\n\u001B[1;32m    877\u001B[0m     dtype \u001B[39m=\u001B[39m torch\u001B[39m.\u001B[39mresult_type(other, \u001B[39mself\u001B[39m)\n\u001B[0;32m--> 878\u001B[0m     \u001B[39mreturn\u001B[39;00m torch\u001B[39m.\u001B[39;49mtensor(other, dtype\u001B[39m=\u001B[39;49mdtype, device\u001B[39m=\u001B[39;49m\u001B[39mself\u001B[39;49m\u001B[39m.\u001B[39;49mdevice) \u001B[39m*\u001B[39m\u001B[39m*\u001B[39m \u001B[39mself\u001B[39m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    #Get enformer Output for training data \n",
    "    storeEnformerOutput(\"training\")\n",
    "    # storeEnformerOutput(\"validation\")\n",
    "    # storeEnformerOutput(\"test\")\n",
    "    verifyStoredEnformerTracks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of samples in all files combined is 212720\n",
      "For index 100, filename : L20-M35.recipient.hdf5 and index within file : 100\n",
      "For index 10000, filename : L20-M35.recipient.hdf5 and index within file : 10000\n",
      "For index 20000, filename : L13-M24.donor.hdf5 and index within file : 483\n",
      "For index 30000, filename : L20-M35.donor.hdf5 and index within file : 3811\n",
      "For index 100000, filename : L10-M12_75.donor.hdf5 and index within file : 186\n"
     ]
    }
   ],
   "source": [
    "#Check if the getting index within file portion is working properly. \n",
    "coordStoreDir = \"/hpc/compgen/projects/fragclass/analysis/mvivekanandan/output/subsetClassBalancedCoordinateFiles\"\n",
    "coordDatasetName = \"trainingCoords\"\n",
    "startIndexList, fileNamesList = utils.createFileNameIndexList(coordStoreDir, coordDatasetName)\n",
    "\n",
    "for index in [100, 10000, 20000, 30000, 100000]:\n",
    "    filePosition = utils.getFilePositionFromIndex(startIndexList, index)\n",
    "    filename = fileNamesList[filePosition]\n",
    "    indexWithinFile = index - startIndexList[filePosition]\n",
    "    print(f\"For index {index}, filename : {filename} and index within file : {indexWithinFile}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:fragenv] *",
   "language": "python",
   "name": "conda-env-fragenv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
