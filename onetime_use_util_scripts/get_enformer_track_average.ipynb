{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'config' from '/hpc/compgen/projects/fragclass/analysis/mvivekanandan/script/madhu_scripts/config.py'>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys \n",
    "sys.path.insert(0,'/hpc/compgen/projects/fragclass/analysis/mvivekanandan/script/madhu_scripts')\n",
    "import importlib\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import torchvision.transforms.functional as tf\n",
    "import pandas as pd\n",
    "\n",
    "import h5py\n",
    "import config \n",
    "import utils\n",
    "\n",
    "importlib.reload(utils)\n",
    "importlib.reload(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DatasetNames\n",
    "arguments = {}\n",
    "\n",
    "arguments[\"trainingEnformerOutputStoreFile\"] = config.filePaths.get(\"trainingEnformerOutputStoreFile\")\n",
    "arguments[\"validationEnformerOutputStoreFile\"] = config.filePaths.get(\"validationEnformerOutputStoreFile\")\n",
    "\n",
    "arguments[\"trainingLabelsDatasetName\"] = config.datasetNames.get(\"trainingLabels\")\n",
    "arguments[\"validationLabelsDatasetName\"] = config.datasetNames.get(\"validationLabels\")\n",
    "arguments[\"testLabelsDatasetName\"] = config.datasetNames.get(\"testLabels\")\n",
    "arguments[\"trainingEnformerOutputDatasetName\"] = config.datasetNames.get(\"trainingEnformerOutput\")\n",
    "arguments[\"validationEnformerOutputDatasetName\"] = config.datasetNames.get(\"validationEnformerOutput\")\n",
    "arguments[\"testEnformerOutputDatasetName\"] = config.datasetNames.get(\"testEnformerOutput\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def averageEnformerOutputBins(samples):\n",
    "    _, numFeatures = samples.shape\n",
    "    first_bin_end_index = int(numFeatures/2)\n",
    "    bin_averaged_output = torch.empty((1,first_bin_end_index))\n",
    "    for sample in samples:\n",
    "        first_bin_outputs = sample[0:first_bin_end_index].reshape(1, first_bin_end_index)\n",
    "        second_bin_outputs = sample[first_bin_end_index: numFeatures].reshape(1, first_bin_end_index)\n",
    "        average = (first_bin_outputs + second_bin_outputs)/2\n",
    "        bin_averaged_output = torch.cat((bin_averaged_output, average), 0)\n",
    "        \n",
    "    return bin_averaged_output[1:, :]\n",
    "\n",
    "def getMinMeanMax(sampleType):\n",
    "    with h5py.File(arguments[f\"{sampleType}EnformerOutputStoreFile\"], 'r') as f:\n",
    "        enformer_output = f[arguments[f\"{sampleType}EnformerOutputDatasetName\"]][0:10000]\n",
    "        encoded_enformer_output = torch.tensor(np.float32(enformer_output))\n",
    "        averaged = averageEnformerOutputBins(encoded_enformer_output).numpy()\n",
    "        print(f\"Shape of {sampleType} averaged: {averaged.shape}\")\n",
    "        min = np.min(averaged, axis = 0).ravel()\n",
    "        max = np.max(averaged, axis = 0).ravel()\n",
    "        mean = np.mean(averaged, axis = 0).ravel()\n",
    "        print(f\"Shapes of {sampleType} min: {min.shape}, max: {max.shape} and mean: {mean.shape}\")\n",
    "        return min, max, mean\n",
    "\n",
    "# training_min, training_max, training_mean = getMinMeanMax(\"training\")\n",
    "# validation_min, validation_max, validation_mean = getMinMeanMax(\"validation\")\n",
    "\n",
    "training_df = pd.DataFrame({'min': training_min, 'max': training_max, \"mean\": training_mean})\n",
    "validation_df = pd.DataFrame({\"min\": validation_min, \"max\": validation_max, \"mean\": validation_mean})\n",
    "\n",
    "training_path = \"/hpc/compgen/projects/fragclass/analysis/mvivekanandan/output/EnformerOutputs/training_enformer_track_averages.csv\"\n",
    "validation_path = \"/hpc/compgen/projects/fragclass/analysis/mvivekanandan/output/EnformerOutputs/validation_enformer_track_averages.csv\"\n",
    "training_df.to_csv(training_path, sep='\\t', index=False)\n",
    "validation_df.to_csv(validation_path, sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:fragenv] *",
   "language": "python",
   "name": "conda-env-fragenv-py"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
