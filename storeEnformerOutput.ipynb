{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pysam\n",
    "import numpy as np\n",
    "import torch\n",
    "import pandas as pd\n",
    "\n",
    "from enformer_pytorch import Enformer\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import h5py\n",
    "import sys\n",
    "\n",
    "sys.path.insert(0,'/hpc/compgen/projects/fragclass/analysis/mvivekanandan/script/madhu_scripts')\n",
    "\n",
    "import config\n",
    "import sequenceUtils\n",
    "\n",
    "import importlib\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "importlib.reload(config)\n",
    "importlib.reload(sequenceUtils)\n",
    "\n",
    "#Set arguments from config file.\n",
    "arguments = {}\n",
    "arguments[\"refGenomePath\"] = config.filePaths.get(\"refGenomePath\")\n",
    "arguments[\"coordStoreDirectory\"] = config.filePaths.get(\"coordStoreDirectory\")\n",
    "arguments[\"enformerOutputStoreFile\"] = config.filePaths.get(\"enformerOutputStoreFile\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"The device used is : {device}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "startIndexList = []\n",
    "fileNamesList = []\n",
    "\n",
    "\"\"\"\n",
    "It iterates through all the files in coordStoreDirectory provided in the config file (in alphabetical order) and stores the starting indices for each file.\n",
    "This is needed because indexing in the dataloader is done for all samples (combined from all files). So given an index, we need to be able to find out which file the corresponding sample should be fetched from.  If we have the starting index for each file, we can compare the index to be fetched with this list and go to the correct file.\n",
    "\n",
    "Output : Returns startIndexList and fileNamesList\n",
    "startIndexList(list of integers) has starting indices of each file. The size of this list will be the number of files in coordinateStoreDirectory\n",
    "fileNamesList (list of string) has the names of all files in the coordinateStoreDirectory. Size will again be the number of files in the directory.\n",
    "\"\"\"\n",
    "def createFileNameIndexList():\n",
    "    coordFilesDirectory = os.fsencode(arguments[\"coordStoreDirectory\"])\n",
    "    currentIndex = 0\n",
    "    for file in os.listdir(coordFilesDirectory):\n",
    "        filename = os.fsencode(file).decode(\"utf-8\")\n",
    "        startIndexList.append(currentIndex)\n",
    "        fileNamesList.append(filename)\n",
    "\n",
    "        numItemsFile = getNumberLinesInFile(filename)\n",
    "        currentIndex = currentIndex + numItemsFile\n",
    "\n",
    "    print(f\"The current index is {currentIndex}\")\n",
    "    return startIndexList, fileNamesList\n",
    "\n",
    "\"\"\"\n",
    "Get the number of samples in a given file by counting the number of lines. This is needed to construct the list of starting indices in the previous function.\n",
    "\n",
    "Args: filename(string) - name of the file for which number of samples needs to be calculated.\n",
    "\n",
    "Output(integer) - number of samples in the given filename.\n",
    "\"\"\"\n",
    "def getNumberLinesInFile(filename):\n",
    "    filePath = arguments[\"coordStoreDirectory\"] + \"/\" + filename\n",
    "    with h5py.File(filePath, 'r') as f:\n",
    "        trainingSamples = f[\"trainingCoords\"][:]\n",
    "        numSamples = len(trainingSamples)\n",
    "        return numSamples\n",
    "\n",
    "\"\"\"\n",
    "Given the list of starting indices of all files in the coordinate store directory, get the filenumber a particular index belongs to\n",
    "\n",
    "Args:\n",
    "startIndexList (list of integers) - list of starting indices of all the files in the coordStoreDirectory\n",
    "indexToFind (integer) - The index for which the file position needs to be returned.\n",
    "\n",
    "Output (integer) - the file number (if all files in the directory are arranged in alphabetical order) which contains the sample correspondng to indexToFind.\n",
    "\"\"\"\n",
    "def getFilePositionFromIndex(startIndexList, indexToFind):\n",
    "   for i, index in enumerate(startIndexList):\n",
    "      if(indexToFind < index):\n",
    "         #This means we moved to the next file, so we have to pick the i before that\n",
    "         filePosition = i-1\n",
    "         return filePosition\n",
    "\n",
    "   #this scenario will never occur unless indexToFind is a negative value.\n",
    "   return -1"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Call the functions to fetch the one hot encoded sequence sequence from a given tuple of coordinates.\n",
    "Args:\n",
    "Coord(tuple): Tuple of coordinates where the values are respectively chromosome number (string), start (string) and end (string) coordinates of the cfdna fragments.\n",
    "\n",
    "Output(string) - torch tensor of a 2D numpy array. The dimensions of the array will be (length * 4) where length is the length of the cfDNA fragment in terms of the number of base pairs.\n",
    "\"\"\"\n",
    "def getOneHotEncodedSequenceFromCoordinates(coord):\n",
    "    referenceGenome = pysam.FastaFile(arguments[\"refGenomePath\"])\n",
    "    coords = (coord[0].decode('UTF-8'), int(coord[1]), int(coord[2]))\n",
    "    #Get surrounding sequence for feeding into enformer.\n",
    "    extendedCoordsForEnformer = sequenceUtils.getCoordsForEnformer(coords, referenceGenome)\n",
    "\n",
    "    #Get the raw sequence using the coordinates and the reference genome.\n",
    "    cfDnaFragment = sequenceUtils.getSequenceFromCoord(referenceGenome, extendedCoordsForEnformer)\n",
    "\n",
    "    #One hot encode sequence\n",
    "    encodedFragment = sequenceUtils.oneHotEncodeSequence(cfDnaFragment)\n",
    "\n",
    "    encoded_input_sequence = torch.tensor(np.float32(encodedFragment))\n",
    "    # encoded_input_sequence = encoded_input_sequence.to(device)\n",
    "    return encoded_input_sequence\n",
    "\n",
    "\"\"\"\n",
    "Given the enformer output and the labels, store them in H5PY files under separate datasets.\n",
    "\n",
    "Args:\n",
    "enformerOutputArray : 1D numpy array(of float numbers) of size [num_batch * 10626]. 5313 is the number of tracks predicted by enformer. We are taking 2 bins from enformer output, and creating a linear array of both the bins. So the output will have 5313 * 2 = 10626 elements. Each element will be output of enformer for one bin, for one track.\n",
    "num_batch is the batch size or the number of samples that are predicted by enformer in parallel. These samples will also be stored in the h5py file in parallel.\n",
    "\n",
    "labelsToStore - 1D numpy array of length num_batch where num_batch is the number of batches. The array will only have 1's and 0's, where 1's represent tumour sample and 0's represant healthy sample.\n",
    "\"\"\"\n",
    "def storeAsH5pyFile(enformerOutputToStore, labelsToStore):\n",
    "   print(\"Inside store as h5py file\")\n",
    "   with h5py.File(arguments[\"enformerOutputStoreFile\"], 'w') as h5_file:\n",
    "      h5_file.create_dataset(\"enformerOutput\", data=enformerOutputToStore, compression=\"gzip\", compression_opts=8)\n",
    "      h5_file.create_dataset(\"labels\", data=labelsToStore, compression=\"gzip\", compression_opts=8)\n",
    "      h5_file.close()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Get the enformer prediction array for a given sequence.\n",
    "\n",
    "Args:\n",
    "enformer_model - the enformer model\n",
    "sequence (2D numpy array of size [length * 4] where length is the number of bases in the sequence). The one hot encoded sequence of cfDNA fragment\n",
    "nbins(int) - number of bins for which enformer output needs to be returned (by default this is set as 2)\n",
    "ntracks(int) - number of tracks output by enformer (In general, this is 5313)\n",
    "\n",
    "Output - 2D numpy array of size [num_batches * 10626] where num_batches is the number of batches and 10626 is the number of tracks (5313) multiplied by the number of bins of output to be returned (2)\n",
    "\"\"\"\n",
    "def getEnformerPredictions(enformer_model, sequence, nbins, ntracks):\n",
    "    print(\"Inside get enformer prediction !!\")\n",
    "    with torch.no_grad():\n",
    "        pretrained_output = enformer_model(sequence)['human'][:, 448:450, :]\n",
    "\n",
    "\n",
    "    # print(f\"Printing the output shape from enformer {pretrained_output.shape}\", flush=True)\n",
    "\n",
    "    #Combine enformer outputs from 2 bins into a single long output. Each bin, each track is a feature. So the total\n",
    "    #number of features for training is num_bins * num_tracks_per_bin. All features can be combined in a\n",
    "    #single 1D tensor array. The other dimension will be the batch size.\n",
    "    print(\"Finished enformer prediction\")\n",
    "    batch_size, nbins, ntracks = pretrained_output.shape\n",
    "\n",
    "    pretrained_output = torch.reshape(pretrained_output, (batch_size, nbins * ntracks))\n",
    "    return pretrained_output"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "The dataset for returning one hot encoded sequence. The samples returned from this dataset will be the input for running enformer model.\n",
    "The getItem method of this dataset calls functions to\n",
    "1. Fetch the filename for the index\n",
    "2. Read the corresponding file from the coordinateStoreDirectory and fetch the coordinates for the samples\n",
    "3. Call functions to get the one hot encoded sequence for the coordinates and return this sequence.\n",
    "\"\"\"\n",
    "class EnformerInputDataset(Dataset):\n",
    "    def __init__(self):\n",
    "        print(\"Initializing the enformer input dataset\")\n",
    "        inputBedFilesDirectory = os.fsencode(arguments[\"inputBedFileFolder\"])\n",
    "        self.inputDirectory = inputBedFilesDirectory\n",
    "        self.startIndexList, self.fileNamesList = createFileNameIndexList\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        filePosition = getFilePositionFromIndex(self.startIndexList, index)\n",
    "        filename = self.fileNamesList[filePosition]\n",
    "        indexWithinFile = index - startIndexList[filePosition]\n",
    "\n",
    "        filepath = os.path.join(arguments[\"coordStoreDirectory\"].decode(\"utf-8\"), filename)\n",
    "\n",
    "        with h5py.File(filepath, 'r') as f:\n",
    "            coord = f['trainingCoords'][indexWithinFile]\n",
    "\n",
    "            #Each sample should have only one label, it should be a single value instead of a numpy 1D array.The [0] is to make it a single value instead of a numpy array.\n",
    "            # label = f['trainingLabels'][index][0]\n",
    "            label = f['trainingLabels'][:][indexWithinFile]\n",
    "\n",
    "            encoded_input_sequence = getOneHotEncodedSequenceFromCoordinates(coord)\n",
    "\n",
    "            #For some cases, the coordinates look fine, but the sequence fetched from the fasta file has size 0.\n",
    "            #If we pass such samples to enformer for predictions, we get Einops error, due to dimension mismatch.\n",
    "            try:\n",
    "                assert encoded_input_sequence.shape == (196607,4)\n",
    "\n",
    "            except:\n",
    "                print(f\"One of the samples did not have the right dimensions. The sample index is {index}, shape is {encoded_input_sequence.shape}\")\n",
    "                return torch.empty((196607,4)), label\n",
    "\n",
    "            return encoded_input_sequence, label\n",
    "\n",
    "    def __len__(self):\n",
    "        with h5py.File(arguments[\"dataFile\"], 'r') as f:\n",
    "            label = f['trainingLabels'][:]\n",
    "            return label.shape[0]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "The function calls functions to get enformerPredictions and to store these predictions in H5PY files. It calls the dataloader for enformerInputDataset. The dataset's getItem returns the one hot encoded cfDNA fragment sequence for each randomly shuffled index. The function for enformerModel prediction for the one hot encoded sequence is then called. The resulting enformer predictions is stored in h5py files along with the labels.\n",
    "\"\"\"\n",
    "def getEnformerOutput():\n",
    "\n",
    "\n",
    "    nbins = 2\n",
    "    ntracks = 5313\n",
    "\n",
    "     #Set the model to eval mode first and then send it to cuda. This prevents the GPU node from running out of memory.\n",
    "    enformerModel = Enformer.from_pretrained('EleutherAI/enformer-official-rough', use_checkpointing = True).eval()\n",
    "    enformerModel = enformerModel.to(device)\n",
    "\n",
    "    #For each bin from enformer output that is considered, the output array from enformer will have ntracks number of values. So the total number of values in enformer output array for a single cfDNA fragment will be nbins * ntracks.\n",
    "    enformer_output_size = (1, nbins*ntracks)\n",
    "    enformer_output_array = np.empty(enformer_output_size)\n",
    "\n",
    "    enformerInputDataset = EnformerInputDataset()\n",
    "    enformerInputDataloader = DataLoader(enformerInputDataset, batch_size=16, num_workers=2)\n",
    "\n",
    "    for i, data in enumerate(enformerInputDataloader, 0):\n",
    "        print(f\"Processing data for batch {i}\", flush = True)\n",
    "\n",
    "        encodedSequence, label = data\n",
    "\n",
    "        #Encoded sequence will have the dimension of [batch_size, 196607, 4]. Get item would have been called batch_size\n",
    "        #number of times. Encoded_input_sequence for some batch items might be empty tensors. So iterate over the encodedSequence\n",
    "        #and remove all the rows which have empty encoded_input_sequence?\n",
    "        # print(f\"Printing the shape of the encoded sequence {encodedSequence.shape}\", flush = )\n",
    "        # print(f\"Printing the shape of label {label.shape}\")\n",
    "\n",
    "        encodedSequence = encodedSequence.to(device)\n",
    "\n",
    "        #The 1st dimension is the batch number. In this case, we have only a single batch, so take the 1st element from the batch dimension directly.\n",
    "        enformerPrediction = getEnformerPredictions(enformerModel, encodedSequence, nbins, ntracks)\n",
    "\n",
    "        #the enformer prediction is still in the GPU (since we sent the enformer model and one hot encoded sequence to the GPU. Numpy arrays are not supported in the GPU(GPU probably supports only tensors). So we pass the enformer prediction to CPU and convert it into a numpy array.\n",
    "        #Detach is used to remove the gradients from the predictions. Gradients are similar to the weights of the model. In our case, we are only interested in the predictions and not the model training, so we remove the gradients to save space.\n",
    "        enformerPrediction = enformerPrediction.detach().cpu().numpy()\n",
    "        print(f\"Finished processsing batch {i}, enformer prediction shape is {enformerPrediction.shape}\")\n",
    "        storeAsH5pyFile(enformerPrediction, label)\n",
    "\n",
    "        # enformer_output_array = np.concatenate((enformer_output_array, enformerPrediction))\n",
    "\n",
    "        # all_inputs = torch.cat(all_inputs, dim = 0)\n",
    "\n",
    "\n",
    "    # #Because we are row wise concatenating the enformer predictions to an empty array, the 1st row is the empty array\n",
    "    # #and it consists of only dummy values. Remove the 1st row from the enformer_output_array\n",
    "    # enformer_output_array = enformer_output_array[1:, :]\n",
    "    # print(f\"Problematic counts are {problem_counts} and size is {len(problem_counts)}\")\n",
    "\n",
    "    return -1, -1"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    enformerOutputArray, labels = getEnformerOutput()\n",
    "    print(f\"Size of enformer output and labels is {enformerOutputArray.shape}, {labels.shape}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
