{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "This file has the functions for\n",
    "1. Reading cfDNA coordinate bed files specified in the \"inputBedFileFolder\" directory specified in the config file\n",
    "2. Partitioning the data into training, validation and test set according to the values \"percentTest\" and \"percent validation\" specified in the config file. Note that this splitting happens in such a way that chromosomes are not shared between the training, test and validation set. cfDNA fragments could have overlapping sequences (due to sequencing depth). Making sure chromosomes are not shared between the different sets would ensure there is no data leakage.\n",
    "3. Stores the output into H5PY files under separate datasets - trainingData, trainingLabels, validationData, validationLabels, testData and testLabels\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import sys\n",
    "import importlib\n",
    "\n",
    "import h5py\n",
    "\n",
    "sys.path.insert(0,'/hpc/compgen/projects/fragclass/analysis/mvivekanandan/script/madhu_scripts')\n",
    "\n",
    "import config\n",
    "import sequenceUtils\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "importlib.reload(config)\n",
    "importlib.reload(sequenceUtils)\n",
    "\n",
    "#Set arguments from config file.\n",
    "arguments = {}\n",
    "arguments[\"donorFile\"] = config.filePaths.get(\"donorFile\")\n",
    "arguments[\"inputBedFileFolder\"] = config.filePaths.get(\"inputBedFileFolder\")\n",
    "arguments['coordStoreDirectory'] = config.filePaths.get(\"coordStoreDirectory\")\n",
    "arguments['snpFilePath'] = config.filePaths.get(\"snpFile\")\n",
    "arguments['coordsStoreFilePath'] = config.filePaths.get(\"coordStoreFile\")\n",
    "arguments['testPercent'] = config.dataCreationConfig.get(\"percentTest\")\n",
    "arguments['validationPercent'] = config.dataCreationConfig.get(\"percentValidation\")\n",
    "arguments['numColsToExtract'] = config.dataCreationConfig.get(\"numColsToExtract\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This function takes a numpy array of training/test/validation data and generates a label array filled with a single value that is provided in label argument.\n",
    "Args:\n",
    "dataNumpy(2D numpy array) - an 2D numpy array data for which labels need to be generated. Note that all samples belonging to this array should have the same label.\n",
    "label(integer) - Single integer. The output labels array will be filled with this value.\n",
    "\n",
    "Output: a 1D array whose length is the same as the number of rows in the dataNumpy.\n",
    "\"\"\"\n",
    "def getLabelsForData(dataNumpy, label):\n",
    "    nrows, ncols = dataNumpy.shape\n",
    "    if label == 0:\n",
    "        return np.zeros(nrows).reshape(nrows, 1)\n",
    "    if label == 1:\n",
    "        return np.ones(nrows).reshape(nrows, 1)\n",
    "    else:\n",
    "        print(f\"Invalid label for data : {label}\")\n",
    "        raise SystemExit(1)\n",
    "\n",
    "\"\"\"\n",
    "This function takes the \"percentage of samples\" column from the file_level_chrom_percent_df(last argument)\n",
    "for a given chromosome(1st argument), adds it to the \"percentage\" argument and returns the sum\n",
    "\n",
    "Args:\n",
    "chrom (string, between 1 and 23, X, Y) - the chromosome number for which the percentage of samples from the input df needs to be\n",
    "         added to the given percentage.\n",
    "percentage (integer or floar value) - percentage to add to the \"percentage of samples\" value in the df\n",
    "file_level_chrom_percent_df (a dataframe with columns #chrom and percentage of samples) - the percentage of samples vs chromosome number df. It should have the columns\n",
    "                              #chrom and \"percentage of samples\".\n",
    "\n",
    "output(integer/float) -  Value of the added percentages.\n",
    "\"\"\"\n",
    "def addPercentagesFunction(chrom, percentage, file_level_chrom_percent_df):\n",
    "    percent_to_add = file_level_chrom_percent_df.loc[file_level_chrom_percent_df[\"#chrom\"] == chrom][\"percentage of samples\"]\n",
    "    if(percent_to_add.values.size == 0):\n",
    "        return percentage\n",
    "    else:\n",
    "        return percentage + percent_to_add.values[0]\n",
    "\n",
    "\"\"\"\n",
    "This function is used to get the average percentage of samples from all the files which belong to each chromosome.\n",
    "\n",
    "Output - returns a dataframe which has the following columns - #chrom and \"percentage of samples\". The #chrom column contains values\n",
    "from 1 to 23, X and Y. \"Percentage of samples\" is the percentage of the total number of fragments that have that chromosome, averaged over all the files in the input bed folder directory.\n",
    "\n",
    "Args:\n",
    "inputBedFilesDirectoryPath - directory which has all the cfDNA fragment bed files.\n",
    "columnNames - column names of the bed files - this is used for reading the bed files into a dataframe.\n",
    "\"\"\"\n",
    "def getChromosomePercentagesAverage(inputBedFilesDirectoryPath, columnNames):\n",
    "    inputBedFilesDirectory = os.fsencode(inputBedFilesDirectoryPath)\n",
    "    all_samples_df = pd.DataFrame(columns=['#chrom', \"percentage of samples\"])\n",
    "\n",
    "    #Insert chromosome numbers.\n",
    "    chroms = range(1, 23)\n",
    "    list_chroms = list(map(lambda chrom: str(chrom), chroms)) + [\"X\"] + [\"Y\"]\n",
    "    all_samples_df[\"#chrom\"] = list_chroms\n",
    "    all_samples_df[\"percentage of samples\"] = [0] * 24\n",
    "\n",
    "    num_files = 0\n",
    "    for file in os.listdir(inputBedFilesDirectory):\n",
    "        filename = os.fsencode(file).decode(\"utf-8\")\n",
    "        filepath = os.path.join(inputBedFilesDirectoryPath.decode(\"utf-8\"), filename)\n",
    "        num_files += 1\n",
    "        cfdna_frag_df = pd.read_csv(filepath, sep = \"\\t\", names = columnNames, skiprows=11)\n",
    "\n",
    "        #If this string conversion is not done, for some files, #chrom till 14 are not strings. This creates problems while\n",
    "        #matching to the string chromosomes from the all_samples_df\n",
    "        cfdna_frag_df[\"#chrom\"]= cfdna_frag_df[\"#chrom\"].map(str)\n",
    "\n",
    "        cfdna_chrom_sample_count = cfdna_frag_df.groupby(\"#chrom\").size().reset_index()\n",
    "        cfdna_chrom_sample_count.columns = [\"#chrom\", \"percentage of samples\"]\n",
    "\n",
    "        #Transform from count to percentage\n",
    "        total_samples = len(cfdna_frag_df)\n",
    "        cfdna_chrom_sample_count[\"percentage of samples\"] = cfdna_chrom_sample_count[\"percentage of samples\"].transform(lambda x: x/total_samples * 100)\n",
    "\n",
    "        # Pick the value from the cfdna_chrom_sample_count where #chrom in the chrom_sample_count df matches the #chrom\n",
    "        # of the row being updated in the all_samples_df. The cdfna_chrom_sample_count.loc returns a pandas series.\n",
    "        # values[0][1] is used to fetch the single int/float value of the percentage.\n",
    "        # All samples should not contain the sum of percentages from all files for each chromosome.\n",
    "        all_samples_df[\"percentage of samples\"] = all_samples_df.apply(lambda x:  addPercentagesFunction(x[\"#chrom\"], x[\"percentage of samples\"], cfdna_chrom_sample_count), axis = 1)\n",
    "\n",
    "    #Take the average of the percentages sum over all files.\n",
    "    all_samples_df[\"percentage of samples\"] =  all_samples_df[\"percentage of samples\"].transform(lambda x: x/num_files)\n",
    "\n",
    "    #Check to see if all the percentages in the final all_samples_df add upto 100.\n",
    "    all_samples_avg = all_samples_df[\"percentage of samples\"]\n",
    "    all_samples_avg_sum = all_samples_avg.sum()\n",
    "    if(round(all_samples_avg_sum) != 100):\n",
    "        raise Exception(f\"********* Something is wrong !! The sum of percentages of all files combined(${all_samples_avg_sum}) is not adding up to 100. \\n After averaging, the all samples df is {all_samples_df.head(25)}\")\n",
    "\n",
    "    return all_samples_df\n",
    "\n",
    "\"\"\"\n",
    "Given a specific percentage to cover, this function returns the list of chromosmes which together account for the maxPercent of samples.\n",
    "\n",
    "Args:\n",
    "df -> The dataframe which has the chromosome numbers and the average percentage of samples covered by this chromosome. This df is expected to have the columns #chrom and \"percentage of samples\".\n",
    "maxPercent -> The percentage that individual chromosome percentage coverage has to add upto.\n",
    "\n",
    "Output - list of chromosomes which cover the given maxPercent\n",
    "\"\"\"\n",
    "def getChromosomesCoveringPercentSamples(df, maxPercent):\n",
    "    chromosomes_list = []\n",
    "    percent_covered = 0\n",
    "    end_index = -1\n",
    "    for i, row in df.iterrows():\n",
    "        chrom = row[\"#chrom\"]\n",
    "        avg_percentage = row[\"percentage of samples\"]\n",
    "        percent_covered = percent_covered + avg_percentage\n",
    "        chromosomes_list.append(chrom)\n",
    "        if(percent_covered > maxPercent):\n",
    "            end_index = i\n",
    "            break\n",
    "    if(end_index) == -1:\n",
    "        raise Exception(\"Something is wrong, the inidividual percentages do not add upto the percentage requested\")\n",
    "\n",
    "    return (end_index, chromosomes_list)\n",
    "\n",
    "\"\"\"\n",
    "This function outputs 3 lists of chromosomes - for training, validation and test.\n",
    "A sample output would be [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12] , [13, 14, 15], [16, 17, 18, 19, 20, 21, 22, X, Y]\n",
    "It internally calls a function that constructs a dataframe that has the average percentage of samples covered by each chromosomes (this averge is constructed by taking all the bed files into account). This is then used to calculate which chromosomes should be part of the training set to reach the trainPercent. The same process is repeated for the validation and test sets with the remaining chromosomes.\n",
    "\n",
    "Args:\n",
    "inputBedFilesDirectoryPath -> The directory which has the bed files\n",
    "columnNames -> Column names inside bed files, this is used to read the bed file into a dataframe\n",
    "trainPercent -> Percentage of samples to be allotted to the train set\n",
    "validationPercent -> Percentage of samples to be alloted to the validation set.\n",
    "\"\"\"\n",
    "def getChromosomeListsForTrainingValidationTest(inputBedFilesDirectoryPath, columnNames, trainPercent, validationPercent):\n",
    "    average_percentage_df = getChromosomePercentagesAverage(inputBedFilesDirectoryPath, columnNames)\n",
    "    (training_end_index, training_chromosomes) = getChromosomesCoveringPercentSamples(average_percentage_df, trainPercent)\n",
    "    (validation_end_index, validation_chromosomes) = getChromosomesCoveringPercentSamples(average_percentage_df.iloc[training_end_index + 1:], validationPercent)\n",
    "\n",
    "    test_chromosomes = average_percentage_df.loc[validation_end_index + 1:][\"#chrom\"].values.tolist()\n",
    "    return (training_chromosomes, validation_chromosomes, test_chromosomes)\n",
    "\n",
    "\"\"\"\n",
    "The validationPercent specified in the config file is relative to the non-test data.\n",
    "If the config file has testPercent and validationPercent as 20 and 20, it means 20% of the 80% non-test data should be used for validation.\n",
    "This function calculates the absolute percentage relative to the entire sample that should belong to the training, validation and test set. It outputs a tuple of absolute training percentage and absolute validation percentage.\n",
    "\"\"\"\n",
    "def getSampleDistributionPercents():\n",
    "    testPercent = arguments[\"testPercent\"]\n",
    "    validationPercent = arguments[\"validationPercent\"]\n",
    "\n",
    "    nonTestPercent = (100 - testPercent)\n",
    "    absValidationPercent = nonTestPercent * validationPercent/100\n",
    "    absTrainingPercent = nonTestPercent * (100 - validationPercent)/100\n",
    "    return (absTrainingPercent, absValidationPercent)\n",
    "\n",
    "\"\"\"\n",
    "This function partitions a given dataframe with cfDNA coordination information into 3 subsets - train, validation and test, based on which chromosome they belong to.\n",
    "\n",
    "Args:\n",
    "cfdna_frag_df -> The dataframe that was created from reading the bed file with coordinates\n",
    "train_chroms -> The list of chromosomes which should belong to the train set\n",
    "validation_chroms -> The list of chromosomes that should belong to the validation set\n",
    "test_chroms -> The list of chromosomes that should belong to the test set,\n",
    "\n",
    "Outputs:\n",
    "cfdna coordinates for training, validation and test subsets.\n",
    "\"\"\"\n",
    "def getTrainTestValidationData(cfdna_frag_df, train_chroms, validation_chroms, test_chroms):\n",
    "    numColumnsToExtract = arguments[\"numColsToExtract\"]\n",
    "    training_df = cfdna_frag_df.loc[cfdna_frag_df[\"#chrom\"].isin(train_chroms)].iloc[:, 0:numColumnsToExtract]\n",
    "    validation_df = cfdna_frag_df.loc[cfdna_frag_df[\"#chrom\"].isin(validation_chroms)].iloc[:, 0:numColumnsToExtract]\n",
    "    test_df = cfdna_frag_df.loc[cfdna_frag_df[\"#chrom\"].isin(test_chroms)].iloc[:, 0:numColumnsToExtract]\n",
    "\n",
    "    return (training_df, validation_df, test_df)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This function does the following\n",
    "1. Iterates through all the files present in inputBedFileFolder directory in config file and reads them as dataframes.\n",
    "2. Calls functions to split the dataframe into training, validation and test dataframes. Also calls functions for label generation\n",
    "3. Writes the training, validation and test data into HDF5 files as different subdatasets within the file.\n",
    "\"\"\"\n",
    "def fetchCoordinatesAndStore():\n",
    "    #ColumnNames in the bed files for reading as a dataframe.\n",
    "    columnNames  = [\"#chrom\", \"start\", \"end\", \"read_id\", \"mapq\", \"cigar1\", \"cigar2\"]\n",
    "\n",
    "    inputBedFilesDirectory = os.fsencode(arguments[\"inputBedFileFolder\"])\n",
    "    trainingPercent, validationPercent = getSampleDistributionPercents()\n",
    "    training_chromosomes, validation_chromosomes, test_chromosomes = getChromosomeListsForTrainingValidationTest(inputBedFilesDirectory, columnNames, trainingPercent, validationPercent)\n",
    "\n",
    "    for file in os.listdir(inputBedFilesDirectory):\n",
    "        filename = os.fsencode(file).decode(\"utf-8\")\n",
    "\n",
    "        if(\"donor.frag.bed.gz\" in filename or \"recipient.frag.bed.gz\" in filename):\n",
    "            label = 0 if \"donor\" in filename else 1\n",
    "\n",
    "            filepath = os.path.join(inputBedFilesDirectory.decode(\"utf-8\"), filename)\n",
    "            cfdna_frag_df = pd.read_csv(filepath,\n",
    "                        sep = \"\\t\", names = columnNames, skiprows=11)\n",
    "\n",
    "            train_data, validation_data, test_data = getTrainTestValidationData(cfdna_frag_df, training_chromosomes, validation_chromosomes, test_chromosomes)\n",
    "\n",
    "            #Get labels for the data\n",
    "            trainingLabels = getLabelsForData(train_data, label)\n",
    "            validationLabels = getLabelsForData(validation_data, label)\n",
    "            testLabels = getLabelsForData(test_data, label)\n",
    "\n",
    "            #Store the data into H5PY files as separate datasets.\n",
    "            coordStoreFilePath = arguments[\"coordStoreDirectory\"] + \"/\" + filename.replace('.frag.bed.gz', '') + \".hdf5\"\n",
    "\n",
    "            with h5py.File(coordStoreFilePath, 'w') as h5_file:\n",
    "                h5_file.create_dataset(\"trainingCoords\", data=train_data.astype(str).to_numpy(), compression = \"gzip\", compression_opts=9)\n",
    "                h5_file.create_dataset(\"trainingLabels\", data=trainingLabels, compression = \"gzip\", compression_opts=9)\n",
    "                h5_file.create_dataset(\"validationCoords\", data=validation_data.astype(str).to_numpy(), compression = \"gzip\", compression_opts=9)\n",
    "                h5_file.create_dataset(\"validationLabels\", data=validationLabels, compression = \"gzip\", compression_opts=9)\n",
    "                h5_file.create_dataset(\"testCoords\", data=test_data.astype(str).to_numpy(), compression = \"gzip\", compression_opts=9)\n",
    "                h5_file.create_dataset(\"testLabels\", data=testLabels, compression = \"gzip\", compression_opts=9)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    print(f\"Arguments is {arguments}\")\n",
    "    fetchCoordinatesAndStore()"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
